{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 공통\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "# 일관된 출력을 위해 유사난수 초기화\n",
    "def reset_graph(seed=42):\n",
    "    tf.reset_default_graph()\n",
    "    tf.set_random_seed(seed)\n",
    "    np.random.seed(seed)\n",
    "\n",
    "# 맷플롯립 설정\n",
    "%matplotlib inline\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "plt.rcParams['axes.labelsize'] = 14\n",
    "plt.rcParams['xtick.labelsize'] = 12\n",
    "plt.rcParams['ytick.labelsize'] = 12\n",
    "\n",
    "# 한글출력\n",
    "plt.rcParams['font.family'] = 'NanumBarunGothic'\n",
    "plt.rcParams['axes.unicode_minus'] = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# CHAPTER 10. 인공 신경망 소개"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 10.1 생물학적 뉴런에서 인공 뉴런까지"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 10.1.1 생물학적 뉴런"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Figure10-1](./images/Figure10-1.png)\n",
    "**<center>그림 10-1 생물학적 뉴런</center>**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "+ **핵**<sup>Nucleus</sup>\n",
    "+ **세포체**<sup>Cell body</sup>\n",
    "+ **수상돌기**<sup>Dendrite</sup>\n",
    "+ **축삭돌기**<sup>Axon</sup>\n",
    "+ **축삭끝가지**<sup>Telodendria</sup>\n",
    "+ **시냅스 말단**<sup>Synaptic terminals</sup>(또는 간단히 **시냅스**<sup>Synapse</sup>)\n",
    "+ 생물학적 뉴런은 이런 시냅스를 통해 다른 뉴런으로부터 짧은 전기 자극 **신호**<sup>signal</sup>를 받음\n",
    "+ 개개의 생물학적 뉴런은 단순하게 동작하지만, 수십억 개의 뉴런이 네트워크로 조직되어 있음"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Figure10-2](./images/Figure10-2.png)\n",
    "**<center>그림 10-2 생물학적 신경망의 여러 층(인간 피질)</center>**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 10.1.2 뉴런을 사용한 논리 연산"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Figure10-3](./images/Figure10-3.png)\n",
    "**<center>그림 10-3 간단한 논리 연산을 수행하는 인공 신경망</center>**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 10.1.3 퍼셉트론<sup>Perceptron</sup>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "+ **TLU**<sup>threshold logic unit</sup> 형태의 인공 뉴런을 기반으로 함\n",
    "+ 입력과 출력이 이진 on/off 값이 아니라 숫자 값"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Figure10-4](./images/Figure10-4.png)\n",
    "**<center>그림 10-4 TLU</center>**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Equation10-1](./images/Equation10-1.png)\n",
    "**<center>식 10-1 퍼셉트론에서 일반적으로 사용하는 계단 함수</center>**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Figure10-5](./images/Figure10-5.png)\n",
    "**<center>그림 10-5 퍼셉트론 다이어그램</center>**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Equation10-2](./images/Equation10-2.png)\n",
    "**<center>식 10-2 퍼셉트론 학습 규칙(가중치 업데이트)</center>**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "+ $w$<sub>$i,j$</sub>는 $i$번째 입력 뉴런과 $j$번째 출력 뉴런 사이를 연결하는 가중치\n",
    "+ $x$<sub>$i$</sub>는 현재 훈련 샘플의 $i$번째 뉴런의 입력값\n",
    "+ $\\hat{y}$<sub>$j$</sub>는 현재 훈련 샘플의 $j$번째 출력 뉴런의 출력값\n",
    "+ $y$<sub>$j$</sub>는 현재 훈련 샘플의 $j$번째 출력 뉴런의 타깃값\n",
    "+ $\\eta$는 학습률"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "+ **퍼셉트론 수렴 이론**<sup>Perceptron convergence theorem</sup> : 훈련 샘플이 선형적으로 구분될 수 있다면 정답에 수렴함"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\link\\Anaconda3\\envs\\mlbook\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:183: FutureWarning: max_iter and tol parameters have been added in Perceptron in 0.19. If max_iter is set but tol is left unset, the default value for tol in 0.19 and 0.20 will be None (which is equivalent to -infinity, so it has no effect) but will change in 0.21 to 1e-3. Specify tol to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([1])"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.linear_model import Perceptron\n",
    "\n",
    "iris = load_iris()\n",
    "X = iris.data[:, (2, 3)]  # 꽃잎 길이, 꽃잎 너비\n",
    "y = (iris.target == 0).astype(np.int)\n",
    "\n",
    "per_clf = Perceptron(max_iter=100, random_state=42)\n",
    "per_clf.fit(X, y)\n",
    "\n",
    "y_pred = per_clf.predict([[2, 0.5]])\n",
    "y_pred"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Figure10-6](./images/Figure10-6.png)\n",
    "**<center>그림 10-6 XOR 분류 문제와 이를 푸는 다층 퍼셉트론</center>**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 10.1.4 다층 퍼셉트론(MLP)과 역전파"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Figure10-7](./images/Figure10-7.png)\n",
    "**<center>그림 10-7 다층 퍼셉트론</center>**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "+ **은닉 층**<sup>hidden layer</sup>이 2개 이상일 때 **심층 신경망**<sup>deep neural network</sup>(DNN)이라고 함"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Figure10-7-1](./images/Figure10-7-1.png)\n",
    "**<center>그림 10-7-1 Backpropagation</center>**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "+ 계단 함수에는 수평선밖에 없어서 계산할 그래디언트가 없음  \n",
    "→ 알고리즘을 잘 작동시키기 위해 계단 함수 대신 **활성화 함수**<sup>activation function</sup>를 사용"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Figure10-8](./images/Figure10-8.png)\n",
    "**<center>그림 10-8 활성화 함수와 해당 도함수</center>**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "+ 각 출력이 서로 다른 이진 클래스에 대응되는 분류 문제에 자주 사용됨\n",
    "+ 클래스가 배타적일 때는 전형적으로 출력층의 활성화 함수를 **소프트맥스**<sup>softmax</sup> 함수를 사용"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Figure10-9](./images/Figure10-9.png)\n",
    "**<center>그림 10-9 분류에 사용되는 (ReLU와 소프트맥스를 포함한) 현대적 다층 퍼셉트론</center>**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "+ **피드포워드 신경망**<sup>feed forward neural network</sup>(FNN) : 신호가 한 방향으로만 흐르는 구조의 신경망"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 10.2 텐서플로의 고수준 API로 다층 퍼셉트론 훈련하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((60000, 28, 28), (60000,), (10000, 28, 28), (10000,))"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "\n",
    "(X_train, y_train), (X_test, y_test) = tf.keras.datasets.mnist.load_data()\n",
    "X_train.shape, y_train.shape ,X_test.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((60000, 784), (10000, 784))"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train = X_train.astype(np.float32).reshape(-1, 28*28) / 255.0\n",
    "X_test = X_test.astype(np.float32).reshape(-1, 28*28) / 255.0\n",
    "X_train.shape, X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = y_train.astype(np.int32)\n",
    "y_test = y_test.astype(np.int32)\n",
    "X_valid, X_train = X_train[:5000], X_train[5000:]\n",
    "y_valid, y_train = y_train[:5000], y_train[5000:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Using default config.\n",
      "WARNING:tensorflow:Using temporary folder as model directory: C:\\Users\\link\\AppData\\Local\\Temp\\tmp11s3czce\n",
      "INFO:tensorflow:Using config: {'_model_dir': 'C:\\\\Users\\\\link\\\\AppData\\\\Local\\\\Temp\\\\tmp11s3czce', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': allow_soft_placement: true\n",
      "graph_options {\n",
      "  rewrite_options {\n",
      "    meta_optimizer_iterations: ONE\n",
      "  }\n",
      "}\n",
      ", '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x0000026BD3244080>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}\n",
      "WARNING:tensorflow:From C:\\Users\\link\\Anaconda3\\envs\\mlbook\\lib\\site-packages\\tensorflow\\python\\estimator\\inputs\\queues\\feeding_queue_runner.py:62: QueueRunner.__init__ (from tensorflow.python.training.queue_runner_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "To construct input pipelines, use the `tf.data` module.\n",
      "WARNING:tensorflow:From C:\\Users\\link\\Anaconda3\\envs\\mlbook\\lib\\site-packages\\tensorflow\\python\\estimator\\inputs\\queues\\feeding_functions.py:500: add_queue_runner (from tensorflow.python.training.queue_runner_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "To construct input pipelines, use the `tf.data` module.\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "WARNING:tensorflow:From C:\\Users\\link\\Anaconda3\\envs\\mlbook\\lib\\site-packages\\tensorflow\\python\\training\\monitored_session.py:804: start_queue_runners (from tensorflow.python.training.queue_runner_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "To construct input pipelines, use the `tf.data` module.\n",
      "INFO:tensorflow:Saving checkpoints for 0 into C:\\Users\\link\\AppData\\Local\\Temp\\tmp11s3czce\\model.ckpt.\n",
      "INFO:tensorflow:loss = 118.694, step = 0\n",
      "INFO:tensorflow:global_step/sec: 256.444\n",
      "INFO:tensorflow:loss = 10.423244, step = 100 (0.390 sec)\n",
      "INFO:tensorflow:global_step/sec: 341.045\n",
      "INFO:tensorflow:loss = 9.091829, step = 200 (0.293 sec)\n",
      "INFO:tensorflow:global_step/sec: 330.915\n",
      "INFO:tensorflow:loss = 4.983379, step = 300 (0.303 sec)\n",
      "INFO:tensorflow:global_step/sec: 312.359\n",
      "INFO:tensorflow:loss = 11.46972, step = 400 (0.320 sec)\n",
      "INFO:tensorflow:global_step/sec: 301.103\n",
      "INFO:tensorflow:loss = 9.6432, step = 500 (0.332 sec)\n",
      "INFO:tensorflow:global_step/sec: 315.305\n",
      "INFO:tensorflow:loss = 5.057374, step = 600 (0.317 sec)\n",
      "INFO:tensorflow:global_step/sec: 311.389\n",
      "INFO:tensorflow:loss = 3.9945264, step = 700 (0.321 sec)\n",
      "INFO:tensorflow:global_step/sec: 338.741\n",
      "INFO:tensorflow:loss = 16.16683, step = 800 (0.295 sec)\n",
      "INFO:tensorflow:global_step/sec: 326.603\n",
      "INFO:tensorflow:loss = 10.255955, step = 900 (0.306 sec)\n",
      "INFO:tensorflow:global_step/sec: 318.309\n",
      "INFO:tensorflow:loss = 6.3254805, step = 1000 (0.314 sec)\n",
      "INFO:tensorflow:global_step/sec: 318.31\n",
      "INFO:tensorflow:loss = 0.688627, step = 1100 (0.314 sec)\n",
      "INFO:tensorflow:global_step/sec: 322.402\n",
      "INFO:tensorflow:loss = 6.7771487, step = 1200 (0.310 sec)\n",
      "INFO:tensorflow:global_step/sec: 329.826\n",
      "INFO:tensorflow:loss = 2.3161654, step = 1300 (0.302 sec)\n",
      "INFO:tensorflow:global_step/sec: 307.568\n",
      "INFO:tensorflow:loss = 3.4935892, step = 1400 (0.327 sec)\n",
      "INFO:tensorflow:global_step/sec: 280.076\n",
      "INFO:tensorflow:loss = 1.6595278, step = 1500 (0.355 sec)\n",
      "INFO:tensorflow:global_step/sec: 329.826\n",
      "INFO:tensorflow:loss = 3.3784256, step = 1600 (0.304 sec)\n",
      "INFO:tensorflow:global_step/sec: 322.404\n",
      "INFO:tensorflow:loss = 1.7129527, step = 1700 (0.309 sec)\n",
      "INFO:tensorflow:global_step/sec: 295.773\n",
      "INFO:tensorflow:loss = 5.963582, step = 1800 (0.339 sec)\n",
      "INFO:tensorflow:global_step/sec: 333.114\n",
      "INFO:tensorflow:loss = 3.363732, step = 1900 (0.300 sec)\n",
      "INFO:tensorflow:global_step/sec: 346.945\n",
      "INFO:tensorflow:loss = 5.5516286, step = 2000 (0.287 sec)\n",
      "INFO:tensorflow:global_step/sec: 317.301\n",
      "INFO:tensorflow:loss = 12.602558, step = 2100 (0.316 sec)\n",
      "INFO:tensorflow:global_step/sec: 295.774\n",
      "INFO:tensorflow:loss = 2.3730865, step = 2200 (0.337 sec)\n",
      "INFO:tensorflow:global_step/sec: 319.323\n",
      "INFO:tensorflow:loss = 4.237853, step = 2300 (0.313 sec)\n",
      "INFO:tensorflow:global_step/sec: 345.748\n",
      "INFO:tensorflow:loss = 1.9098232, step = 2400 (0.290 sec)\n",
      "INFO:tensorflow:global_step/sec: 318.309\n",
      "INFO:tensorflow:loss = 2.495726, step = 2500 (0.314 sec)\n",
      "INFO:tensorflow:global_step/sec: 278.52\n",
      "INFO:tensorflow:loss = 3.4519105, step = 2600 (0.359 sec)\n",
      "INFO:tensorflow:global_step/sec: 316.297\n",
      "INFO:tensorflow:loss = 4.0739155, step = 2700 (0.317 sec)\n",
      "INFO:tensorflow:global_step/sec: 306.63\n",
      "INFO:tensorflow:loss = 5.5204477, step = 2800 (0.325 sec)\n",
      "INFO:tensorflow:global_step/sec: 309.467\n",
      "INFO:tensorflow:loss = 2.633893, step = 2900 (0.323 sec)\n",
      "INFO:tensorflow:global_step/sec: 324.491\n",
      "INFO:tensorflow:loss = 0.62115824, step = 3000 (0.307 sec)\n",
      "INFO:tensorflow:global_step/sec: 294.038\n",
      "INFO:tensorflow:loss = 1.5036194, step = 3100 (0.341 sec)\n",
      "INFO:tensorflow:global_step/sec: 330.915\n",
      "INFO:tensorflow:loss = 0.8230472, step = 3200 (0.302 sec)\n",
      "INFO:tensorflow:global_step/sec: 291.475\n",
      "INFO:tensorflow:loss = 2.987803, step = 3300 (0.342 sec)\n",
      "INFO:tensorflow:global_step/sec: 295.773\n",
      "INFO:tensorflow:loss = 3.3158631, step = 3400 (0.338 sec)\n",
      "INFO:tensorflow:global_step/sec: 332.011\n",
      "INFO:tensorflow:loss = 5.0548663, step = 3500 (0.301 sec)\n",
      "INFO:tensorflow:global_step/sec: 337.6\n",
      "INFO:tensorflow:loss = 2.186643, step = 3600 (0.297 sec)\n",
      "INFO:tensorflow:global_step/sec: 299.305\n",
      "INFO:tensorflow:loss = 1.6498146, step = 3700 (0.333 sec)\n",
      "INFO:tensorflow:global_step/sec: 343.382\n",
      "INFO:tensorflow:loss = 0.86388683, step = 3800 (0.292 sec)\n",
      "INFO:tensorflow:global_step/sec: 345.749\n",
      "INFO:tensorflow:loss = 1.9271935, step = 3900 (0.288 sec)\n",
      "INFO:tensorflow:global_step/sec: 348.15\n",
      "INFO:tensorflow:loss = 3.4714432, step = 4000 (0.288 sec)\n",
      "INFO:tensorflow:global_step/sec: 311.389\n",
      "INFO:tensorflow:loss = 5.1418223, step = 4100 (0.320 sec)\n",
      "INFO:tensorflow:global_step/sec: 337.6\n",
      "INFO:tensorflow:loss = 0.37628996, step = 4200 (0.297 sec)\n",
      "INFO:tensorflow:global_step/sec: 299.305\n",
      "INFO:tensorflow:loss = 0.15927087, step = 4300 (0.333 sec)\n",
      "INFO:tensorflow:global_step/sec: 335.342\n",
      "INFO:tensorflow:loss = 1.1386532, step = 4400 (0.299 sec)\n",
      "INFO:tensorflow:global_step/sec: 330.914\n",
      "INFO:tensorflow:loss = 4.4458876, step = 4500 (0.302 sec)\n",
      "INFO:tensorflow:global_step/sec: 309.468\n",
      "INFO:tensorflow:loss = 0.284359, step = 4600 (0.322 sec)\n",
      "INFO:tensorflow:global_step/sec: 348.149\n",
      "INFO:tensorflow:loss = 0.4810959, step = 4700 (0.288 sec)\n",
      "INFO:tensorflow:global_step/sec: 323.443\n",
      "INFO:tensorflow:loss = 0.23538262, step = 4800 (0.309 sec)\n",
      "INFO:tensorflow:global_step/sec: 318.309\n",
      "INFO:tensorflow:loss = 1.0329348, step = 4900 (0.313 sec)\n",
      "INFO:tensorflow:global_step/sec: 329.827\n",
      "INFO:tensorflow:loss = 1.2158862, step = 5000 (0.304 sec)\n",
      "INFO:tensorflow:global_step/sec: 324.489\n",
      "INFO:tensorflow:loss = 1.7434216, step = 5100 (0.308 sec)\n",
      "INFO:tensorflow:global_step/sec: 282.443\n",
      "INFO:tensorflow:loss = 3.4889715, step = 5200 (0.355 sec)\n",
      "INFO:tensorflow:global_step/sec: 344.561\n",
      "INFO:tensorflow:loss = 1.1057886, step = 5300 (0.289 sec)\n",
      "INFO:tensorflow:global_step/sec: 300.2\n",
      "INFO:tensorflow:loss = 0.29289475, step = 5400 (0.332 sec)\n",
      "INFO:tensorflow:global_step/sec: 312.358\n",
      "INFO:tensorflow:loss = 1.9812573, step = 5500 (0.321 sec)\n",
      "INFO:tensorflow:global_step/sec: 301.104\n",
      "INFO:tensorflow:loss = 0.75403535, step = 5600 (0.331 sec)\n",
      "INFO:tensorflow:global_step/sec: 325.543\n",
      "INFO:tensorflow:loss = 5.6450443, step = 5700 (0.308 sec)\n",
      "INFO:tensorflow:global_step/sec: 321.369\n",
      "INFO:tensorflow:loss = 2.1443167, step = 5800 (0.311 sec)\n",
      "INFO:tensorflow:global_step/sec: 308.514\n",
      "INFO:tensorflow:loss = 0.3908174, step = 5900 (0.325 sec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 294.039\n",
      "INFO:tensorflow:loss = 0.3755817, step = 6000 (0.338 sec)\n",
      "INFO:tensorflow:global_step/sec: 349.363\n",
      "INFO:tensorflow:loss = 12.512836, step = 6100 (0.287 sec)\n",
      "INFO:tensorflow:global_step/sec: 342.209\n",
      "INFO:tensorflow:loss = 0.84577435, step = 6200 (0.292 sec)\n",
      "INFO:tensorflow:global_step/sec: 302.01\n",
      "INFO:tensorflow:loss = 1.1087593, step = 6300 (0.331 sec)\n",
      "INFO:tensorflow:global_step/sec: 343.382\n",
      "INFO:tensorflow:loss = 7.1294475, step = 6400 (0.291 sec)\n",
      "INFO:tensorflow:global_step/sec: 353.054\n",
      "INFO:tensorflow:loss = 0.27368137, step = 6500 (0.282 sec)\n",
      "INFO:tensorflow:global_step/sec: 350.584\n",
      "INFO:tensorflow:loss = 0.6790308, step = 6600 (0.285 sec)\n",
      "INFO:tensorflow:global_step/sec: 329.826\n",
      "INFO:tensorflow:loss = 0.5001973, step = 6700 (0.303 sec)\n",
      "INFO:tensorflow:global_step/sec: 302.922\n",
      "INFO:tensorflow:loss = 0.53347594, step = 6800 (0.331 sec)\n",
      "INFO:tensorflow:global_step/sec: 337.601\n",
      "INFO:tensorflow:loss = 0.11546424, step = 6900 (0.295 sec)\n",
      "INFO:tensorflow:global_step/sec: 349.363\n",
      "INFO:tensorflow:loss = 0.17365412, step = 7000 (0.286 sec)\n",
      "INFO:tensorflow:global_step/sec: 283.24\n",
      "INFO:tensorflow:loss = 0.54413134, step = 7100 (0.355 sec)\n",
      "INFO:tensorflow:global_step/sec: 311.389\n",
      "INFO:tensorflow:loss = 0.3526999, step = 7200 (0.320 sec)\n",
      "INFO:tensorflow:global_step/sec: 338.741\n",
      "INFO:tensorflow:loss = 0.29481208, step = 7300 (0.294 sec)\n",
      "INFO:tensorflow:global_step/sec: 351.816\n",
      "INFO:tensorflow:loss = 0.06336355, step = 7400 (0.284 sec)\n",
      "INFO:tensorflow:global_step/sec: 311.389\n",
      "INFO:tensorflow:loss = 0.23911867, step = 7500 (0.321 sec)\n",
      "INFO:tensorflow:global_step/sec: 351.815\n",
      "INFO:tensorflow:loss = 0.61373806, step = 7600 (0.285 sec)\n",
      "INFO:tensorflow:global_step/sec: 300.201\n",
      "INFO:tensorflow:loss = 0.26437545, step = 7700 (0.333 sec)\n",
      "INFO:tensorflow:global_step/sec: 349.363\n",
      "INFO:tensorflow:loss = 0.36923096, step = 7800 (0.286 sec)\n",
      "INFO:tensorflow:global_step/sec: 329.826\n",
      "INFO:tensorflow:loss = 0.15157829, step = 7900 (0.302 sec)\n",
      "INFO:tensorflow:global_step/sec: 310.425\n",
      "INFO:tensorflow:loss = 0.08638769, step = 8000 (0.323 sec)\n",
      "INFO:tensorflow:global_step/sec: 345.749\n",
      "INFO:tensorflow:loss = 0.060039073, step = 8100 (0.288 sec)\n",
      "INFO:tensorflow:global_step/sec: 345.749\n",
      "INFO:tensorflow:loss = 0.08764446, step = 8200 (0.290 sec)\n",
      "INFO:tensorflow:global_step/sec: 329.827\n",
      "INFO:tensorflow:loss = 0.6142357, step = 8300 (0.302 sec)\n",
      "INFO:tensorflow:global_step/sec: 336.468\n",
      "INFO:tensorflow:loss = 0.43143904, step = 8400 (0.298 sec)\n",
      "INFO:tensorflow:global_step/sec: 334.224\n",
      "INFO:tensorflow:loss = 0.3405334, step = 8500 (0.299 sec)\n",
      "INFO:tensorflow:global_step/sec: 298.414\n",
      "INFO:tensorflow:loss = 0.14358762, step = 8600 (0.335 sec)\n",
      "INFO:tensorflow:global_step/sec: 341.045\n",
      "INFO:tensorflow:loss = 0.5728335, step = 8700 (0.293 sec)\n",
      "INFO:tensorflow:global_step/sec: 338.74\n",
      "INFO:tensorflow:loss = 1.1218523, step = 8800 (0.294 sec)\n",
      "INFO:tensorflow:global_step/sec: 326.601\n",
      "INFO:tensorflow:loss = 0.28494838, step = 8900 (0.307 sec)\n",
      "INFO:tensorflow:global_step/sec: 302.012\n",
      "INFO:tensorflow:loss = 2.2854128, step = 9000 (0.330 sec)\n",
      "INFO:tensorflow:global_step/sec: 344.561\n",
      "INFO:tensorflow:loss = 0.32896549, step = 9100 (0.290 sec)\n",
      "INFO:tensorflow:global_step/sec: 342.209\n",
      "INFO:tensorflow:loss = 0.18508956, step = 9200 (0.293 sec)\n",
      "INFO:tensorflow:global_step/sec: 320.343\n",
      "INFO:tensorflow:loss = 0.034701426, step = 9300 (0.311 sec)\n",
      "INFO:tensorflow:global_step/sec: 327.671\n",
      "INFO:tensorflow:loss = 0.13923596, step = 9400 (0.305 sec)\n",
      "INFO:tensorflow:global_step/sec: 351.815\n",
      "INFO:tensorflow:loss = 0.8833997, step = 9500 (0.284 sec)\n",
      "INFO:tensorflow:global_step/sec: 336.465\n",
      "INFO:tensorflow:loss = 0.2702018, step = 9600 (0.298 sec)\n",
      "INFO:tensorflow:global_step/sec: 353.056\n",
      "INFO:tensorflow:loss = 0.20804107, step = 9700 (0.282 sec)\n",
      "INFO:tensorflow:global_step/sec: 302.922\n",
      "INFO:tensorflow:loss = 0.36581063, step = 9800 (0.331 sec)\n",
      "INFO:tensorflow:global_step/sec: 325.544\n",
      "INFO:tensorflow:loss = 0.25258645, step = 9900 (0.307 sec)\n",
      "INFO:tensorflow:global_step/sec: 337.599\n",
      "INFO:tensorflow:loss = 0.21645325, step = 10000 (0.296 sec)\n",
      "INFO:tensorflow:global_step/sec: 330.915\n",
      "INFO:tensorflow:loss = 0.24835706, step = 10100 (0.302 sec)\n",
      "INFO:tensorflow:global_step/sec: 309.468\n",
      "INFO:tensorflow:loss = 0.28716767, step = 10200 (0.323 sec)\n",
      "INFO:tensorflow:global_step/sec: 350.584\n",
      "INFO:tensorflow:loss = 0.25887513, step = 10300 (0.284 sec)\n",
      "INFO:tensorflow:global_step/sec: 343.381\n",
      "INFO:tensorflow:loss = 0.09302555, step = 10400 (0.291 sec)\n",
      "INFO:tensorflow:global_step/sec: 346.944\n",
      "INFO:tensorflow:loss = 0.053590026, step = 10500 (0.289 sec)\n",
      "INFO:tensorflow:global_step/sec: 327.672\n",
      "INFO:tensorflow:loss = 0.10856733, step = 10600 (0.305 sec)\n",
      "INFO:tensorflow:global_step/sec: 344.561\n",
      "INFO:tensorflow:loss = 0.23608792, step = 10700 (0.290 sec)\n",
      "INFO:tensorflow:global_step/sec: 322.402\n",
      "INFO:tensorflow:loss = 0.24233562, step = 10800 (0.309 sec)\n",
      "INFO:tensorflow:global_step/sec: 348.15\n",
      "INFO:tensorflow:loss = 0.03810243, step = 10900 (0.289 sec)\n",
      "INFO:tensorflow:global_step/sec: 314.319\n",
      "INFO:tensorflow:loss = 0.12911382, step = 11000 (0.316 sec)\n",
      "INFO:tensorflow:global_step/sec: 317.302\n",
      "INFO:tensorflow:loss = 0.19721098, step = 11100 (0.316 sec)\n",
      "INFO:tensorflow:global_step/sec: 333.113\n",
      "INFO:tensorflow:loss = 0.47061324, step = 11200 (0.299 sec)\n",
      "INFO:tensorflow:global_step/sec: 326.604\n",
      "INFO:tensorflow:loss = 0.015678434, step = 11300 (0.307 sec)\n",
      "INFO:tensorflow:global_step/sec: 307.568\n",
      "INFO:tensorflow:loss = 0.1513604, step = 11400 (0.326 sec)\n",
      "INFO:tensorflow:global_step/sec: 330.914\n",
      "INFO:tensorflow:loss = 0.0936925, step = 11500 (0.301 sec)\n",
      "INFO:tensorflow:global_step/sec: 351.816\n",
      "INFO:tensorflow:loss = 0.43604922, step = 11600 (0.284 sec)\n",
      "INFO:tensorflow:global_step/sec: 333.113\n",
      "INFO:tensorflow:loss = 0.20666185, step = 11700 (0.301 sec)\n",
      "INFO:tensorflow:global_step/sec: 319.322\n",
      "INFO:tensorflow:loss = 0.111144856, step = 11800 (0.312 sec)\n",
      "INFO:tensorflow:global_step/sec: 345.75\n",
      "INFO:tensorflow:loss = 0.33269346, step = 11900 (0.288 sec)\n",
      "INFO:tensorflow:global_step/sec: 351.814\n",
      "INFO:tensorflow:loss = 0.34035817, step = 12000 (0.284 sec)\n",
      "INFO:tensorflow:global_step/sec: 326.603\n",
      "INFO:tensorflow:loss = 0.20177706, step = 12100 (0.306 sec)\n",
      "INFO:tensorflow:global_step/sec: 346.946\n",
      "INFO:tensorflow:loss = 0.28806862, step = 12200 (0.289 sec)\n",
      "INFO:tensorflow:global_step/sec: 351.815\n",
      "INFO:tensorflow:loss = 0.039679788, step = 12300 (0.284 sec)\n",
      "INFO:tensorflow:global_step/sec: 348.15\n",
      "INFO:tensorflow:loss = 0.16023903, step = 12400 (0.287 sec)\n",
      "INFO:tensorflow:global_step/sec: 328.744\n",
      "INFO:tensorflow:loss = 0.04707143, step = 12500 (0.304 sec)\n",
      "INFO:tensorflow:global_step/sec: 330.916\n",
      "INFO:tensorflow:loss = 0.108479485, step = 12600 (0.302 sec)\n",
      "INFO:tensorflow:global_step/sec: 320.343\n",
      "INFO:tensorflow:loss = 0.092934206, step = 12700 (0.312 sec)\n",
      "INFO:tensorflow:global_step/sec: 334.225\n",
      "INFO:tensorflow:loss = 0.20852657, step = 12800 (0.298 sec)\n",
      "INFO:tensorflow:global_step/sec: 323.442\n",
      "INFO:tensorflow:loss = 0.2568356, step = 12900 (0.309 sec)\n",
      "INFO:tensorflow:global_step/sec: 351.815\n",
      "INFO:tensorflow:loss = 0.38840628, step = 13000 (0.285 sec)\n",
      "INFO:tensorflow:global_step/sec: 320.343\n",
      "INFO:tensorflow:loss = 0.59077585, step = 13100 (0.312 sec)\n",
      "INFO:tensorflow:global_step/sec: 345.749\n",
      "INFO:tensorflow:loss = 0.11749962, step = 13200 (0.290 sec)\n",
      "INFO:tensorflow:global_step/sec: 325.542\n",
      "INFO:tensorflow:loss = 1.1027644, step = 13300 (0.306 sec)\n",
      "INFO:tensorflow:global_step/sec: 332.012\n",
      "INFO:tensorflow:loss = 0.17489912, step = 13400 (0.300 sec)\n",
      "INFO:tensorflow:global_step/sec: 339.888\n",
      "INFO:tensorflow:loss = 0.107556276, step = 13500 (0.294 sec)\n",
      "INFO:tensorflow:global_step/sec: 345.749\n",
      "INFO:tensorflow:loss = 0.08776597, step = 13600 (0.290 sec)\n",
      "INFO:tensorflow:global_step/sec: 319.323\n",
      "INFO:tensorflow:loss = 0.04211098, step = 13700 (0.312 sec)\n",
      "INFO:tensorflow:global_step/sec: 328.745\n",
      "INFO:tensorflow:loss = 0.26246148, step = 13800 (0.305 sec)\n",
      "INFO:tensorflow:global_step/sec: 350.585\n",
      "INFO:tensorflow:loss = 0.17615634, step = 13900 (0.285 sec)\n",
      "INFO:tensorflow:global_step/sec: 336.465\n",
      "INFO:tensorflow:loss = 0.153442, step = 14000 (0.297 sec)\n",
      "INFO:tensorflow:global_step/sec: 329.827\n",
      "INFO:tensorflow:loss = 0.14293541, step = 14100 (0.302 sec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 351.816\n",
      "INFO:tensorflow:loss = 0.07563539, step = 14200 (0.285 sec)\n",
      "INFO:tensorflow:global_step/sec: 344.559\n",
      "INFO:tensorflow:loss = 7.3370123, step = 14300 (0.290 sec)\n",
      "INFO:tensorflow:global_step/sec: 338.741\n",
      "INFO:tensorflow:loss = 0.19483253, step = 14400 (0.295 sec)\n",
      "INFO:tensorflow:global_step/sec: 336.468\n",
      "INFO:tensorflow:loss = 0.028300187, step = 14500 (0.296 sec)\n",
      "INFO:tensorflow:global_step/sec: 337.599\n",
      "INFO:tensorflow:loss = 0.72543234, step = 14600 (0.296 sec)\n",
      "INFO:tensorflow:global_step/sec: 324.49\n",
      "INFO:tensorflow:loss = 0.11211136, step = 14700 (0.309 sec)\n",
      "INFO:tensorflow:global_step/sec: 322.403\n",
      "INFO:tensorflow:loss = 0.12904906, step = 14800 (0.310 sec)\n",
      "INFO:tensorflow:global_step/sec: 330.915\n",
      "INFO:tensorflow:loss = 0.15222552, step = 14900 (0.301 sec)\n",
      "INFO:tensorflow:global_step/sec: 315.305\n",
      "INFO:tensorflow:loss = 0.29641616, step = 15000 (0.318 sec)\n",
      "INFO:tensorflow:global_step/sec: 333.114\n",
      "INFO:tensorflow:loss = 0.19041187, step = 15100 (0.300 sec)\n",
      "INFO:tensorflow:global_step/sec: 316.3\n",
      "INFO:tensorflow:loss = 0.051088724, step = 15200 (0.315 sec)\n",
      "INFO:tensorflow:global_step/sec: 295.773\n",
      "INFO:tensorflow:loss = 0.037981443, step = 15300 (0.338 sec)\n",
      "INFO:tensorflow:global_step/sec: 338.742\n",
      "INFO:tensorflow:loss = 0.09861463, step = 15400 (0.295 sec)\n",
      "INFO:tensorflow:global_step/sec: 332.01\n",
      "INFO:tensorflow:loss = 0.105352804, step = 15500 (0.302 sec)\n",
      "INFO:tensorflow:global_step/sec: 286.478\n",
      "INFO:tensorflow:loss = 0.0814928, step = 15600 (0.349 sec)\n",
      "INFO:tensorflow:global_step/sec: 325.543\n",
      "INFO:tensorflow:loss = 0.12082981, step = 15700 (0.306 sec)\n",
      "INFO:tensorflow:global_step/sec: 311.389\n",
      "INFO:tensorflow:loss = 0.024558222, step = 15800 (0.322 sec)\n",
      "INFO:tensorflow:global_step/sec: 289.789\n",
      "INFO:tensorflow:loss = 0.010827336, step = 15900 (0.345 sec)\n",
      "INFO:tensorflow:global_step/sec: 306.628\n",
      "INFO:tensorflow:loss = 0.10578006, step = 16000 (0.326 sec)\n",
      "INFO:tensorflow:global_step/sec: 291.474\n",
      "INFO:tensorflow:loss = 0.26204762, step = 16100 (0.342 sec)\n",
      "INFO:tensorflow:global_step/sec: 284.85\n",
      "INFO:tensorflow:loss = 0.054132726, step = 16200 (0.352 sec)\n",
      "INFO:tensorflow:global_step/sec: 311.389\n",
      "INFO:tensorflow:loss = 0.09092711, step = 16300 (0.320 sec)\n",
      "INFO:tensorflow:global_step/sec: 315.306\n",
      "INFO:tensorflow:loss = 0.092787296, step = 16400 (0.317 sec)\n",
      "INFO:tensorflow:global_step/sec: 332.01\n",
      "INFO:tensorflow:loss = 0.05555433, step = 16500 (0.301 sec)\n",
      "INFO:tensorflow:global_step/sec: 303.84\n",
      "INFO:tensorflow:loss = 0.06474291, step = 16600 (0.332 sec)\n",
      "INFO:tensorflow:global_step/sec: 276.981\n",
      "INFO:tensorflow:loss = 0.35916963, step = 16700 (0.360 sec)\n",
      "INFO:tensorflow:global_step/sec: 310.425\n",
      "INFO:tensorflow:loss = 0.03238096, step = 16800 (0.322 sec)\n",
      "INFO:tensorflow:global_step/sec: 328.745\n",
      "INFO:tensorflow:loss = 0.05300006, step = 16900 (0.303 sec)\n",
      "INFO:tensorflow:global_step/sec: 283.241\n",
      "INFO:tensorflow:loss = 0.024066703, step = 17000 (0.353 sec)\n",
      "INFO:tensorflow:global_step/sec: 332.01\n",
      "INFO:tensorflow:loss = 0.10821759, step = 17100 (0.300 sec)\n",
      "INFO:tensorflow:global_step/sec: 343.381\n",
      "INFO:tensorflow:loss = 0.15236235, step = 17200 (0.291 sec)\n",
      "INFO:tensorflow:global_step/sec: 325.543\n",
      "INFO:tensorflow:loss = 0.0020154885, step = 17300 (0.309 sec)\n",
      "INFO:tensorflow:global_step/sec: 298.414\n",
      "INFO:tensorflow:loss = 0.047082834, step = 17400 (0.334 sec)\n",
      "INFO:tensorflow:global_step/sec: 341.045\n",
      "INFO:tensorflow:loss = 0.06491834, step = 17500 (0.293 sec)\n",
      "INFO:tensorflow:global_step/sec: 342.209\n",
      "INFO:tensorflow:loss = 0.0024690868, step = 17600 (0.291 sec)\n",
      "INFO:tensorflow:global_step/sec: 341.045\n",
      "INFO:tensorflow:loss = 0.23767397, step = 17700 (0.294 sec)\n",
      "INFO:tensorflow:global_step/sec: 323.443\n",
      "INFO:tensorflow:loss = 0.06059312, step = 17800 (0.309 sec)\n",
      "INFO:tensorflow:global_step/sec: 303.84\n",
      "INFO:tensorflow:loss = 0.048438013, step = 17900 (0.329 sec)\n",
      "INFO:tensorflow:global_step/sec: 333.114\n",
      "INFO:tensorflow:loss = 0.031201232, step = 18000 (0.300 sec)\n",
      "INFO:tensorflow:global_step/sec: 288.954\n",
      "INFO:tensorflow:loss = 0.019978058, step = 18100 (0.348 sec)\n",
      "INFO:tensorflow:global_step/sec: 270.993\n",
      "INFO:tensorflow:loss = 0.10122819, step = 18200 (0.367 sec)\n",
      "INFO:tensorflow:global_step/sec: 337.6\n",
      "INFO:tensorflow:loss = 0.25097886, step = 18300 (0.295 sec)\n",
      "INFO:tensorflow:global_step/sec: 341.045\n",
      "INFO:tensorflow:loss = 0.01741742, step = 18400 (0.293 sec)\n",
      "INFO:tensorflow:global_step/sec: 292.324\n",
      "INFO:tensorflow:loss = 0.240215, step = 18500 (0.343 sec)\n",
      "INFO:tensorflow:global_step/sec: 326.603\n",
      "INFO:tensorflow:loss = 0.082374334, step = 18600 (0.306 sec)\n",
      "INFO:tensorflow:global_step/sec: 342.209\n",
      "INFO:tensorflow:loss = 0.05770683, step = 18700 (0.292 sec)\n",
      "INFO:tensorflow:global_step/sec: 328.745\n",
      "INFO:tensorflow:loss = 0.06665674, step = 18800 (0.303 sec)\n",
      "INFO:tensorflow:global_step/sec: 304.764\n",
      "INFO:tensorflow:loss = 0.0041913316, step = 18900 (0.328 sec)\n",
      "INFO:tensorflow:global_step/sec: 342.209\n",
      "INFO:tensorflow:loss = 0.041083932, step = 19000 (0.292 sec)\n",
      "INFO:tensorflow:global_step/sec: 344.561\n",
      "INFO:tensorflow:loss = 0.066014245, step = 19100 (0.291 sec)\n",
      "INFO:tensorflow:global_step/sec: 332.011\n",
      "INFO:tensorflow:loss = 0.003557243, step = 19200 (0.301 sec)\n",
      "INFO:tensorflow:global_step/sec: 326.602\n",
      "INFO:tensorflow:loss = 0.04218459, step = 19300 (0.306 sec)\n",
      "INFO:tensorflow:global_step/sec: 300.203\n",
      "INFO:tensorflow:loss = 0.05614227, step = 19400 (0.333 sec)\n",
      "INFO:tensorflow:global_step/sec: 343.38\n",
      "INFO:tensorflow:loss = 0.03888821, step = 19500 (0.291 sec)\n",
      "INFO:tensorflow:global_step/sec: 328.746\n",
      "INFO:tensorflow:loss = 0.12842128, step = 19600 (0.304 sec)\n",
      "INFO:tensorflow:global_step/sec: 298.414\n",
      "INFO:tensorflow:loss = 0.066975474, step = 19700 (0.335 sec)\n",
      "INFO:tensorflow:global_step/sec: 348.15\n",
      "INFO:tensorflow:loss = 0.054618835, step = 19800 (0.287 sec)\n",
      "INFO:tensorflow:global_step/sec: 342.209\n",
      "INFO:tensorflow:loss = 0.054082215, step = 19900 (0.292 sec)\n",
      "INFO:tensorflow:global_step/sec: 324.49\n",
      "INFO:tensorflow:loss = 0.039822377, step = 20000 (0.307 sec)\n",
      "INFO:tensorflow:global_step/sec: 338.741\n",
      "INFO:tensorflow:loss = 0.0068068616, step = 20100 (0.295 sec)\n",
      "INFO:tensorflow:global_step/sec: 322.401\n",
      "INFO:tensorflow:loss = 0.06715774, step = 20200 (0.311 sec)\n",
      "INFO:tensorflow:global_step/sec: 324.491\n",
      "INFO:tensorflow:loss = 0.069356315, step = 20300 (0.307 sec)\n",
      "INFO:tensorflow:global_step/sec: 324.49\n",
      "INFO:tensorflow:loss = 0.00881312, step = 20400 (0.308 sec)\n",
      "INFO:tensorflow:global_step/sec: 335.342\n",
      "INFO:tensorflow:loss = 0.034740005, step = 20500 (0.298 sec)\n",
      "INFO:tensorflow:global_step/sec: 318.308\n",
      "INFO:tensorflow:loss = 0.30080512, step = 20600 (0.314 sec)\n",
      "INFO:tensorflow:global_step/sec: 338.741\n",
      "INFO:tensorflow:loss = 0.10443982, step = 20700 (0.295 sec)\n",
      "INFO:tensorflow:global_step/sec: 326.603\n",
      "INFO:tensorflow:loss = 0.108347125, step = 20800 (0.307 sec)\n",
      "INFO:tensorflow:global_step/sec: 345.749\n",
      "INFO:tensorflow:loss = 0.024251768, step = 20900 (0.289 sec)\n",
      "INFO:tensorflow:global_step/sec: 345.747\n",
      "INFO:tensorflow:loss = 0.042598367, step = 21000 (0.289 sec)\n",
      "INFO:tensorflow:global_step/sec: 302.921\n",
      "INFO:tensorflow:loss = 0.03738755, step = 21100 (0.331 sec)\n",
      "INFO:tensorflow:global_step/sec: 323.446\n",
      "INFO:tensorflow:loss = 0.017862061, step = 21200 (0.308 sec)\n",
      "INFO:tensorflow:global_step/sec: 348.15\n",
      "INFO:tensorflow:loss = 0.06921079, step = 21300 (0.286 sec)\n",
      "INFO:tensorflow:global_step/sec: 321.37\n",
      "INFO:tensorflow:loss = 0.11825374, step = 21400 (0.311 sec)\n",
      "INFO:tensorflow:global_step/sec: 317.3\n",
      "INFO:tensorflow:loss = 0.030026883, step = 21500 (0.316 sec)\n",
      "INFO:tensorflow:global_step/sec: 337.602\n",
      "INFO:tensorflow:loss = 0.017215978, step = 21600 (0.296 sec)\n",
      "INFO:tensorflow:global_step/sec: 346.945\n",
      "INFO:tensorflow:loss = 0.026147824, step = 21700 (0.287 sec)\n",
      "INFO:tensorflow:global_step/sec: 346.946\n",
      "INFO:tensorflow:loss = 0.08528414, step = 21800 (0.288 sec)\n",
      "INFO:tensorflow:global_step/sec: 325.542\n",
      "INFO:tensorflow:loss = 0.10856208, step = 21900 (0.309 sec)\n",
      "INFO:tensorflow:global_step/sec: 291.475\n",
      "INFO:tensorflow:loss = 0.11399727, step = 22000 (0.342 sec)\n",
      "INFO:tensorflow:global_step/sec: 345.749\n",
      "INFO:tensorflow:loss = 0.01651135, step = 22100 (0.289 sec)\n",
      "INFO:tensorflow:global_step/sec: 345.749\n",
      "INFO:tensorflow:loss = 0.015664106, step = 22200 (0.288 sec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 295.774\n",
      "INFO:tensorflow:loss = 0.14736281, step = 22300 (0.339 sec)\n",
      "INFO:tensorflow:global_step/sec: 338.74\n",
      "INFO:tensorflow:loss = 0.04170479, step = 22400 (0.294 sec)\n",
      "INFO:tensorflow:global_step/sec: 350.584\n",
      "INFO:tensorflow:loss = 0.04132849, step = 22500 (0.286 sec)\n",
      "INFO:tensorflow:global_step/sec: 323.443\n",
      "INFO:tensorflow:loss = 0.10253537, step = 22600 (0.308 sec)\n",
      "INFO:tensorflow:global_step/sec: 324.49\n",
      "INFO:tensorflow:loss = 0.016451241, step = 22700 (0.308 sec)\n",
      "INFO:tensorflow:global_step/sec: 350.585\n",
      "INFO:tensorflow:loss = 0.0411376, step = 22800 (0.286 sec)\n",
      "INFO:tensorflow:global_step/sec: 346.945\n",
      "INFO:tensorflow:loss = 0.08194381, step = 22900 (0.288 sec)\n",
      "INFO:tensorflow:global_step/sec: 345.749\n",
      "INFO:tensorflow:loss = 0.031336386, step = 23000 (0.288 sec)\n",
      "INFO:tensorflow:global_step/sec: 313.335\n",
      "INFO:tensorflow:loss = 0.006905762, step = 23100 (0.320 sec)\n",
      "INFO:tensorflow:global_step/sec: 316.3\n",
      "INFO:tensorflow:loss = 0.07559003, step = 23200 (0.316 sec)\n",
      "INFO:tensorflow:global_step/sec: 350.585\n",
      "INFO:tensorflow:loss = 0.05214482, step = 23300 (0.285 sec)\n",
      "INFO:tensorflow:global_step/sec: 342.21\n",
      "INFO:tensorflow:loss = 0.021301983, step = 23400 (0.291 sec)\n",
      "INFO:tensorflow:global_step/sec: 302.009\n",
      "INFO:tensorflow:loss = 0.049489442, step = 23500 (0.332 sec)\n",
      "INFO:tensorflow:global_step/sec: 351.816\n",
      "INFO:tensorflow:loss = 0.11102272, step = 23600 (0.284 sec)\n",
      "INFO:tensorflow:global_step/sec: 349.363\n",
      "INFO:tensorflow:loss = 0.06707705, step = 23700 (0.285 sec)\n",
      "INFO:tensorflow:global_step/sec: 337.601\n",
      "INFO:tensorflow:loss = 0.055230007, step = 23800 (0.297 sec)\n",
      "INFO:tensorflow:global_step/sec: 325.543\n",
      "INFO:tensorflow:loss = 0.1232062, step = 23900 (0.306 sec)\n",
      "INFO:tensorflow:global_step/sec: 321.369\n",
      "INFO:tensorflow:loss = 0.05764281, step = 24000 (0.311 sec)\n",
      "INFO:tensorflow:global_step/sec: 328.745\n",
      "INFO:tensorflow:loss = 0.012696935, step = 24100 (0.304 sec)\n",
      "INFO:tensorflow:global_step/sec: 334.224\n",
      "INFO:tensorflow:loss = 0.040873833, step = 24200 (0.300 sec)\n",
      "INFO:tensorflow:global_step/sec: 327.669\n",
      "INFO:tensorflow:loss = 0.013768646, step = 24300 (0.306 sec)\n",
      "INFO:tensorflow:global_step/sec: 323.445\n",
      "INFO:tensorflow:loss = 0.017481657, step = 24400 (0.308 sec)\n",
      "INFO:tensorflow:global_step/sec: 351.814\n",
      "INFO:tensorflow:loss = 0.027889216, step = 24500 (0.284 sec)\n",
      "INFO:tensorflow:global_step/sec: 328.745\n",
      "INFO:tensorflow:loss = 0.07970842, step = 24600 (0.304 sec)\n",
      "INFO:tensorflow:global_step/sec: 337.6\n",
      "INFO:tensorflow:loss = 0.013758814, step = 24700 (0.296 sec)\n",
      "INFO:tensorflow:global_step/sec: 343.381\n",
      "INFO:tensorflow:loss = 0.0103458855, step = 24800 (0.292 sec)\n",
      "INFO:tensorflow:global_step/sec: 304.764\n",
      "INFO:tensorflow:loss = 0.2829548, step = 24900 (0.327 sec)\n",
      "INFO:tensorflow:global_step/sec: 316.301\n",
      "INFO:tensorflow:loss = 0.021871008, step = 25000 (0.316 sec)\n",
      "INFO:tensorflow:global_step/sec: 342.209\n",
      "INFO:tensorflow:loss = 0.02705733, step = 25100 (0.292 sec)\n",
      "INFO:tensorflow:global_step/sec: 320.343\n",
      "INFO:tensorflow:loss = 0.00662171, step = 25200 (0.312 sec)\n",
      "INFO:tensorflow:global_step/sec: 321.368\n",
      "INFO:tensorflow:loss = 0.053238075, step = 25300 (0.311 sec)\n",
      "INFO:tensorflow:global_step/sec: 326.604\n",
      "INFO:tensorflow:loss = 0.14119011, step = 25400 (0.305 sec)\n",
      "INFO:tensorflow:global_step/sec: 332.01\n",
      "INFO:tensorflow:loss = 0.041326847, step = 25500 (0.301 sec)\n",
      "INFO:tensorflow:global_step/sec: 341.045\n",
      "INFO:tensorflow:loss = 0.0103886835, step = 25600 (0.294 sec)\n",
      "INFO:tensorflow:global_step/sec: 339.889\n",
      "INFO:tensorflow:loss = 0.043643773, step = 25700 (0.294 sec)\n",
      "INFO:tensorflow:global_step/sec: 330.915\n",
      "INFO:tensorflow:loss = 0.064527065, step = 25800 (0.302 sec)\n",
      "INFO:tensorflow:global_step/sec: 344.561\n",
      "INFO:tensorflow:loss = 0.015641266, step = 25900 (0.289 sec)\n",
      "INFO:tensorflow:global_step/sec: 349.363\n",
      "INFO:tensorflow:loss = 0.019864732, step = 26000 (0.286 sec)\n",
      "INFO:tensorflow:global_step/sec: 296.648\n",
      "INFO:tensorflow:loss = 0.028493179, step = 26100 (0.338 sec)\n",
      "INFO:tensorflow:global_step/sec: 336.467\n",
      "INFO:tensorflow:loss = 0.031406328, step = 26200 (0.296 sec)\n",
      "INFO:tensorflow:global_step/sec: 349.363\n",
      "INFO:tensorflow:loss = 0.06039398, step = 26300 (0.286 sec)\n",
      "INFO:tensorflow:global_step/sec: 313.335\n",
      "INFO:tensorflow:loss = 0.0021532222, step = 26400 (0.319 sec)\n",
      "INFO:tensorflow:global_step/sec: 329.827\n",
      "INFO:tensorflow:loss = 0.030460935, step = 26500 (0.303 sec)\n",
      "INFO:tensorflow:global_step/sec: 333.114\n",
      "INFO:tensorflow:loss = 0.013410778, step = 26600 (0.300 sec)\n",
      "INFO:tensorflow:global_step/sec: 348.15\n",
      "INFO:tensorflow:loss = 0.017807802, step = 26700 (0.288 sec)\n",
      "INFO:tensorflow:global_step/sec: 348.149\n",
      "INFO:tensorflow:loss = 0.040684897, step = 26800 (0.286 sec)\n",
      "INFO:tensorflow:global_step/sec: 314.315\n",
      "INFO:tensorflow:loss = 0.028239165, step = 26900 (0.320 sec)\n",
      "INFO:tensorflow:global_step/sec: 312.361\n",
      "INFO:tensorflow:loss = 0.044321824, step = 27000 (0.319 sec)\n",
      "INFO:tensorflow:global_step/sec: 349.364\n",
      "INFO:tensorflow:loss = 0.021859156, step = 27100 (0.285 sec)\n",
      "INFO:tensorflow:global_step/sec: 345.749\n",
      "INFO:tensorflow:loss = 0.016853407, step = 27200 (0.289 sec)\n",
      "INFO:tensorflow:global_step/sec: 292.324\n",
      "INFO:tensorflow:loss = 0.050081763, step = 27300 (0.343 sec)\n",
      "INFO:tensorflow:global_step/sec: 344.561\n",
      "INFO:tensorflow:loss = 0.024971304, step = 27400 (0.289 sec)\n",
      "INFO:tensorflow:global_step/sec: 332.011\n",
      "INFO:tensorflow:loss = 0.060217842, step = 27500 (0.302 sec)\n",
      "INFO:tensorflow:global_step/sec: 316.3\n",
      "INFO:tensorflow:loss = 0.039358146, step = 27600 (0.316 sec)\n",
      "INFO:tensorflow:global_step/sec: 324.49\n",
      "INFO:tensorflow:loss = 0.011786552, step = 27700 (0.307 sec)\n",
      "INFO:tensorflow:global_step/sec: 348.15\n",
      "INFO:tensorflow:loss = 0.029683394, step = 27800 (0.287 sec)\n",
      "INFO:tensorflow:global_step/sec: 341.045\n",
      "INFO:tensorflow:loss = 0.016310217, step = 27900 (0.293 sec)\n",
      "INFO:tensorflow:global_step/sec: 338.741\n",
      "INFO:tensorflow:loss = 0.006489965, step = 28000 (0.296 sec)\n",
      "INFO:tensorflow:global_step/sec: 302.922\n",
      "INFO:tensorflow:loss = 0.07444583, step = 28100 (0.330 sec)\n",
      "INFO:tensorflow:global_step/sec: 332.011\n",
      "INFO:tensorflow:loss = 0.18151653, step = 28200 (0.300 sec)\n",
      "INFO:tensorflow:global_step/sec: 349.363\n",
      "INFO:tensorflow:loss = 0.024854003, step = 28300 (0.287 sec)\n",
      "INFO:tensorflow:global_step/sec: 323.441\n",
      "INFO:tensorflow:loss = 0.023819704, step = 28400 (0.309 sec)\n",
      "INFO:tensorflow:global_step/sec: 315.306\n",
      "INFO:tensorflow:loss = 0.1325626, step = 28500 (0.317 sec)\n",
      "INFO:tensorflow:global_step/sec: 348.151\n",
      "INFO:tensorflow:loss = 0.020114953, step = 28600 (0.287 sec)\n",
      "INFO:tensorflow:global_step/sec: 349.362\n",
      "INFO:tensorflow:loss = 0.037250895, step = 28700 (0.285 sec)\n",
      "INFO:tensorflow:global_step/sec: 333.114\n",
      "INFO:tensorflow:loss = 0.06899054, step = 28800 (0.300 sec)\n",
      "INFO:tensorflow:global_step/sec: 332.008\n",
      "INFO:tensorflow:loss = 0.07048187, step = 28900 (0.301 sec)\n",
      "INFO:tensorflow:global_step/sec: 304.766\n",
      "INFO:tensorflow:loss = 0.14143056, step = 29000 (0.328 sec)\n",
      "INFO:tensorflow:global_step/sec: 345.747\n",
      "INFO:tensorflow:loss = 0.012683311, step = 29100 (0.290 sec)\n",
      "INFO:tensorflow:global_step/sec: 328.747\n",
      "INFO:tensorflow:loss = 0.036423065, step = 29200 (0.304 sec)\n",
      "INFO:tensorflow:global_step/sec: 308.514\n",
      "INFO:tensorflow:loss = 0.008429006, step = 29300 (0.323 sec)\n",
      "INFO:tensorflow:global_step/sec: 342.208\n",
      "INFO:tensorflow:loss = 0.03995072, step = 29400 (0.293 sec)\n",
      "INFO:tensorflow:global_step/sec: 348.151\n",
      "INFO:tensorflow:loss = 0.026484916, step = 29500 (0.286 sec)\n",
      "INFO:tensorflow:global_step/sec: 327.671\n",
      "INFO:tensorflow:loss = 0.0025267473, step = 29600 (0.306 sec)\n",
      "INFO:tensorflow:global_step/sec: 341.045\n",
      "INFO:tensorflow:loss = 0.022549624, step = 29700 (0.292 sec)\n",
      "INFO:tensorflow:global_step/sec: 345.748\n",
      "INFO:tensorflow:loss = 0.048094, step = 29800 (0.290 sec)\n",
      "INFO:tensorflow:global_step/sec: 302.01\n",
      "INFO:tensorflow:loss = 0.0062940232, step = 29900 (0.331 sec)\n",
      "INFO:tensorflow:global_step/sec: 326.604\n",
      "INFO:tensorflow:loss = 0.05897694, step = 30000 (0.307 sec)\n",
      "INFO:tensorflow:global_step/sec: 348.151\n",
      "INFO:tensorflow:loss = 0.0065713264, step = 30100 (0.286 sec)\n",
      "INFO:tensorflow:global_step/sec: 304.764\n",
      "INFO:tensorflow:loss = 0.0022440003, step = 30200 (0.327 sec)\n",
      "INFO:tensorflow:global_step/sec: 337.6\n",
      "INFO:tensorflow:loss = 0.03879478, step = 30300 (0.297 sec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 329.826\n",
      "INFO:tensorflow:loss = 0.018173363, step = 30400 (0.302 sec)\n",
      "INFO:tensorflow:global_step/sec: 321.369\n",
      "INFO:tensorflow:loss = 0.053593688, step = 30500 (0.311 sec)\n",
      "INFO:tensorflow:global_step/sec: 348.15\n",
      "INFO:tensorflow:loss = 0.03936865, step = 30600 (0.288 sec)\n",
      "INFO:tensorflow:global_step/sec: 335.342\n",
      "INFO:tensorflow:loss = 0.007256469, step = 30700 (0.297 sec)\n",
      "INFO:tensorflow:global_step/sec: 335.342\n",
      "INFO:tensorflow:loss = 0.021481397, step = 30800 (0.298 sec)\n",
      "INFO:tensorflow:global_step/sec: 346.946\n",
      "INFO:tensorflow:loss = 0.008789353, step = 30900 (0.288 sec)\n",
      "INFO:tensorflow:global_step/sec: 341.044\n",
      "INFO:tensorflow:loss = 0.03036324, step = 31000 (0.293 sec)\n",
      "INFO:tensorflow:global_step/sec: 305.693\n",
      "INFO:tensorflow:loss = 0.020313986, step = 31100 (0.327 sec)\n",
      "INFO:tensorflow:global_step/sec: 335.342\n",
      "INFO:tensorflow:loss = 0.009918319, step = 31200 (0.299 sec)\n",
      "INFO:tensorflow:global_step/sec: 351.816\n",
      "INFO:tensorflow:loss = 0.023779236, step = 31300 (0.283 sec)\n",
      "INFO:tensorflow:global_step/sec: 308.514\n",
      "INFO:tensorflow:loss = 0.020955617, step = 31400 (0.324 sec)\n",
      "INFO:tensorflow:global_step/sec: 328.744\n",
      "INFO:tensorflow:loss = 0.18301831, step = 31500 (0.305 sec)\n",
      "INFO:tensorflow:global_step/sec: 338.742\n",
      "INFO:tensorflow:loss = 0.14615762, step = 31600 (0.294 sec)\n",
      "INFO:tensorflow:global_step/sec: 349.363\n",
      "INFO:tensorflow:loss = 0.05866799, step = 31700 (0.286 sec)\n",
      "INFO:tensorflow:global_step/sec: 351.814\n",
      "INFO:tensorflow:loss = 0.022598345, step = 31800 (0.285 sec)\n",
      "INFO:tensorflow:global_step/sec: 307.569\n",
      "INFO:tensorflow:loss = 0.012851122, step = 31900 (0.325 sec)\n",
      "INFO:tensorflow:global_step/sec: 319.322\n",
      "INFO:tensorflow:loss = 0.017372172, step = 32000 (0.313 sec)\n",
      "INFO:tensorflow:global_step/sec: 350.585\n",
      "INFO:tensorflow:loss = 0.04486938, step = 32100 (0.284 sec)\n",
      "INFO:tensorflow:global_step/sec: 344.56\n",
      "INFO:tensorflow:loss = 0.009376286, step = 32200 (0.291 sec)\n",
      "INFO:tensorflow:global_step/sec: 302.923\n",
      "INFO:tensorflow:loss = 0.010878438, step = 32300 (0.329 sec)\n",
      "INFO:tensorflow:global_step/sec: 345.749\n",
      "INFO:tensorflow:loss = 0.0056247814, step = 32400 (0.289 sec)\n",
      "INFO:tensorflow:global_step/sec: 346.945\n",
      "INFO:tensorflow:loss = 0.047146704, step = 32500 (0.288 sec)\n",
      "INFO:tensorflow:global_step/sec: 345.75\n",
      "INFO:tensorflow:loss = 0.03767491, step = 32600 (0.289 sec)\n",
      "INFO:tensorflow:global_step/sec: 301.102\n",
      "INFO:tensorflow:loss = 0.023008123, step = 32700 (0.332 sec)\n",
      "INFO:tensorflow:global_step/sec: 315.305\n",
      "INFO:tensorflow:loss = 0.016543705, step = 32800 (0.318 sec)\n",
      "INFO:tensorflow:global_step/sec: 337.602\n",
      "INFO:tensorflow:loss = 0.11041308, step = 32900 (0.295 sec)\n",
      "INFO:tensorflow:global_step/sec: 328.743\n",
      "INFO:tensorflow:loss = 0.0029686391, step = 33000 (0.305 sec)\n",
      "INFO:tensorflow:global_step/sec: 311.39\n",
      "INFO:tensorflow:loss = 0.00501655, step = 33100 (0.320 sec)\n",
      "INFO:tensorflow:global_step/sec: 333.114\n",
      "INFO:tensorflow:loss = 0.014919331, step = 33200 (0.301 sec)\n",
      "INFO:tensorflow:global_step/sec: 349.363\n",
      "INFO:tensorflow:loss = 0.017577158, step = 33300 (0.285 sec)\n",
      "INFO:tensorflow:global_step/sec: 323.443\n",
      "INFO:tensorflow:loss = 0.010446486, step = 33400 (0.309 sec)\n",
      "INFO:tensorflow:global_step/sec: 334.223\n",
      "INFO:tensorflow:loss = 0.030529376, step = 33500 (0.300 sec)\n",
      "INFO:tensorflow:global_step/sec: 349.364\n",
      "INFO:tensorflow:loss = 0.016369725, step = 33600 (0.285 sec)\n",
      "INFO:tensorflow:global_step/sec: 304.763\n",
      "INFO:tensorflow:loss = 0.02752928, step = 33700 (0.328 sec)\n",
      "INFO:tensorflow:global_step/sec: 332.011\n",
      "INFO:tensorflow:loss = 0.01384358, step = 33800 (0.302 sec)\n",
      "INFO:tensorflow:global_step/sec: 335.342\n",
      "INFO:tensorflow:loss = 0.066223845, step = 33900 (0.298 sec)\n",
      "INFO:tensorflow:global_step/sec: 315.306\n",
      "INFO:tensorflow:loss = 0.0044842605, step = 34000 (0.316 sec)\n",
      "INFO:tensorflow:global_step/sec: 342.209\n",
      "INFO:tensorflow:loss = 0.005535527, step = 34100 (0.292 sec)\n",
      "INFO:tensorflow:global_step/sec: 328.745\n",
      "INFO:tensorflow:loss = 0.032772914, step = 34200 (0.305 sec)\n",
      "INFO:tensorflow:global_step/sec: 323.443\n",
      "INFO:tensorflow:loss = 0.018072113, step = 34300 (0.309 sec)\n",
      "INFO:tensorflow:global_step/sec: 345.749\n",
      "INFO:tensorflow:loss = 0.010952229, step = 34400 (0.288 sec)\n",
      "INFO:tensorflow:global_step/sec: 344.561\n",
      "INFO:tensorflow:loss = 0.022935089, step = 34500 (0.290 sec)\n",
      "INFO:tensorflow:global_step/sec: 326.602\n",
      "INFO:tensorflow:loss = 0.010686066, step = 34600 (0.307 sec)\n",
      "INFO:tensorflow:global_step/sec: 346.946\n",
      "INFO:tensorflow:loss = 0.025830928, step = 34700 (0.288 sec)\n",
      "INFO:tensorflow:global_step/sec: 346.946\n",
      "INFO:tensorflow:loss = 0.008472773, step = 34800 (0.287 sec)\n",
      "INFO:tensorflow:global_step/sec: 300.201\n",
      "INFO:tensorflow:loss = 0.019884327, step = 34900 (0.334 sec)\n",
      "INFO:tensorflow:global_step/sec: 330.915\n",
      "INFO:tensorflow:loss = 0.038405277, step = 35000 (0.301 sec)\n",
      "INFO:tensorflow:global_step/sec: 350.585\n",
      "INFO:tensorflow:loss = 0.0006543643, step = 35100 (0.285 sec)\n",
      "INFO:tensorflow:global_step/sec: 307.568\n",
      "INFO:tensorflow:loss = 0.00013446441, step = 35200 (0.326 sec)\n",
      "INFO:tensorflow:global_step/sec: 335.341\n",
      "INFO:tensorflow:loss = 0.029711792, step = 35300 (0.298 sec)\n",
      "INFO:tensorflow:global_step/sec: 332.012\n",
      "INFO:tensorflow:loss = 0.013202735, step = 35400 (0.300 sec)\n",
      "INFO:tensorflow:global_step/sec: 346.945\n",
      "INFO:tensorflow:loss = 0.017826922, step = 35500 (0.288 sec)\n",
      "INFO:tensorflow:global_step/sec: 350.585\n",
      "INFO:tensorflow:loss = 0.017476335, step = 35600 (0.285 sec)\n",
      "INFO:tensorflow:global_step/sec: 328.743\n",
      "INFO:tensorflow:loss = 0.0059206905, step = 35700 (0.305 sec)\n",
      "INFO:tensorflow:global_step/sec: 304.767\n",
      "INFO:tensorflow:loss = 0.00096965954, step = 35800 (0.328 sec)\n",
      "INFO:tensorflow:global_step/sec: 344.56\n",
      "INFO:tensorflow:loss = 0.022049816, step = 35900 (0.290 sec)\n",
      "INFO:tensorflow:global_step/sec: 343.381\n",
      "INFO:tensorflow:loss = 0.005321511, step = 36000 (0.290 sec)\n",
      "INFO:tensorflow:global_step/sec: 296.648\n",
      "INFO:tensorflow:loss = 0.026568204, step = 36100 (0.337 sec)\n",
      "INFO:tensorflow:global_step/sec: 337.6\n",
      "INFO:tensorflow:loss = 0.004301035, step = 36200 (0.297 sec)\n",
      "INFO:tensorflow:global_step/sec: 349.364\n",
      "INFO:tensorflow:loss = 0.0023062075, step = 36300 (0.285 sec)\n",
      "INFO:tensorflow:global_step/sec: 322.403\n",
      "INFO:tensorflow:loss = 0.035134967, step = 36400 (0.310 sec)\n",
      "INFO:tensorflow:global_step/sec: 328.745\n",
      "INFO:tensorflow:loss = 0.018110728, step = 36500 (0.305 sec)\n",
      "INFO:tensorflow:global_step/sec: 339.889\n",
      "INFO:tensorflow:loss = 0.021516621, step = 36600 (0.293 sec)\n",
      "INFO:tensorflow:global_step/sec: 348.15\n",
      "INFO:tensorflow:loss = 0.00999504, step = 36700 (0.287 sec)\n",
      "INFO:tensorflow:global_step/sec: 349.362\n",
      "INFO:tensorflow:loss = 0.019136107, step = 36800 (0.286 sec)\n",
      "INFO:tensorflow:global_step/sec: 307.568\n",
      "INFO:tensorflow:loss = 0.06414555, step = 36900 (0.326 sec)\n",
      "INFO:tensorflow:global_step/sec: 322.403\n",
      "INFO:tensorflow:loss = 0.010595721, step = 37000 (0.309 sec)\n",
      "INFO:tensorflow:global_step/sec: 346.946\n",
      "INFO:tensorflow:loss = 0.018219829, step = 37100 (0.288 sec)\n",
      "INFO:tensorflow:global_step/sec: 338.74\n",
      "INFO:tensorflow:loss = 0.021059843, step = 37200 (0.295 sec)\n",
      "INFO:tensorflow:global_step/sec: 308.515\n",
      "INFO:tensorflow:loss = 0.021246728, step = 37300 (0.325 sec)\n",
      "INFO:tensorflow:global_step/sec: 345.749\n",
      "INFO:tensorflow:loss = 0.006575836, step = 37400 (0.289 sec)\n",
      "INFO:tensorflow:global_step/sec: 348.151\n",
      "INFO:tensorflow:loss = 0.012512171, step = 37500 (0.287 sec)\n",
      "INFO:tensorflow:global_step/sec: 317.301\n",
      "INFO:tensorflow:loss = 0.017715078, step = 37600 (0.315 sec)\n",
      "INFO:tensorflow:global_step/sec: 330.916\n",
      "INFO:tensorflow:loss = 0.020597605, step = 37700 (0.302 sec)\n",
      "INFO:tensorflow:global_step/sec: 350.584\n",
      "INFO:tensorflow:loss = 0.010807216, step = 37800 (0.284 sec)\n",
      "INFO:tensorflow:global_step/sec: 342.209\n",
      "INFO:tensorflow:loss = 0.014012744, step = 37900 (0.298 sec)\n",
      "INFO:tensorflow:global_step/sec: 332.011\n",
      "INFO:tensorflow:loss = 0.02491294, step = 38000 (0.296 sec)\n",
      "INFO:tensorflow:global_step/sec: 308.514\n",
      "INFO:tensorflow:loss = 0.000523391, step = 38100 (0.324 sec)\n",
      "INFO:tensorflow:global_step/sec: 335.342\n",
      "INFO:tensorflow:loss = 0.014207202, step = 38200 (0.298 sec)\n",
      "INFO:tensorflow:global_step/sec: 348.151\n",
      "INFO:tensorflow:loss = 0.0007371075, step = 38300 (0.287 sec)\n",
      "INFO:tensorflow:global_step/sec: 309.464\n",
      "INFO:tensorflow:loss = 0.008022518, step = 38400 (0.323 sec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 325.546\n",
      "INFO:tensorflow:loss = 0.056337953, step = 38500 (0.307 sec)\n",
      "INFO:tensorflow:global_step/sec: 348.15\n",
      "INFO:tensorflow:loss = 0.020796543, step = 38600 (0.286 sec)\n",
      "INFO:tensorflow:global_step/sec: 350.585\n",
      "INFO:tensorflow:loss = 0.0076301303, step = 38700 (0.285 sec)\n",
      "INFO:tensorflow:global_step/sec: 334.223\n",
      "INFO:tensorflow:loss = 0.005468433, step = 38800 (0.300 sec)\n",
      "INFO:tensorflow:global_step/sec: 327.671\n",
      "INFO:tensorflow:loss = 0.026583642, step = 38900 (0.305 sec)\n",
      "INFO:tensorflow:global_step/sec: 307.569\n",
      "INFO:tensorflow:loss = 0.028222168, step = 39000 (0.324 sec)\n",
      "INFO:tensorflow:global_step/sec: 349.363\n",
      "INFO:tensorflow:loss = 0.0055801016, step = 39100 (0.286 sec)\n",
      "INFO:tensorflow:global_step/sec: 327.67\n",
      "INFO:tensorflow:loss = 0.012595018, step = 39200 (0.306 sec)\n",
      "INFO:tensorflow:global_step/sec: 302.923\n",
      "INFO:tensorflow:loss = 0.0015620094, step = 39300 (0.330 sec)\n",
      "INFO:tensorflow:global_step/sec: 350.584\n",
      "INFO:tensorflow:loss = 0.02903568, step = 39400 (0.284 sec)\n",
      "INFO:tensorflow:global_step/sec: 344.561\n",
      "INFO:tensorflow:loss = 0.0046302364, step = 39500 (0.290 sec)\n",
      "INFO:tensorflow:global_step/sec: 334.224\n",
      "INFO:tensorflow:loss = 0.009353859, step = 39600 (0.301 sec)\n",
      "INFO:tensorflow:global_step/sec: 341.044\n",
      "INFO:tensorflow:loss = 0.03104842, step = 39700 (0.292 sec)\n",
      "INFO:tensorflow:global_step/sec: 335.342\n",
      "INFO:tensorflow:loss = 0.001394578, step = 39800 (0.298 sec)\n",
      "INFO:tensorflow:global_step/sec: 303.84\n",
      "INFO:tensorflow:loss = 0.018380787, step = 39900 (0.329 sec)\n",
      "INFO:tensorflow:global_step/sec: 332.011\n",
      "INFO:tensorflow:loss = 0.024030514, step = 40000 (0.300 sec)\n",
      "INFO:tensorflow:global_step/sec: 349.363\n",
      "INFO:tensorflow:loss = 0.001197629, step = 40100 (0.286 sec)\n",
      "INFO:tensorflow:global_step/sec: 300.201\n",
      "INFO:tensorflow:loss = 0.044824865, step = 40200 (0.334 sec)\n",
      "INFO:tensorflow:global_step/sec: 312.359\n",
      "INFO:tensorflow:loss = 0.03276854, step = 40300 (0.320 sec)\n",
      "INFO:tensorflow:global_step/sec: 332.011\n",
      "INFO:tensorflow:loss = 0.014378389, step = 40400 (0.301 sec)\n",
      "INFO:tensorflow:global_step/sec: 324.489\n",
      "INFO:tensorflow:loss = 0.041786812, step = 40500 (0.307 sec)\n",
      "INFO:tensorflow:global_step/sec: 346.946\n",
      "INFO:tensorflow:loss = 0.004221171, step = 40600 (0.289 sec)\n",
      "INFO:tensorflow:global_step/sec: 333.114\n",
      "INFO:tensorflow:loss = 0.007876594, step = 40700 (0.300 sec)\n",
      "INFO:tensorflow:global_step/sec: 333.113\n",
      "INFO:tensorflow:loss = 0.050099112, step = 40800 (0.299 sec)\n",
      "INFO:tensorflow:global_step/sec: 343.381\n",
      "INFO:tensorflow:loss = 0.017301539, step = 40900 (0.292 sec)\n",
      "INFO:tensorflow:global_step/sec: 315.305\n",
      "INFO:tensorflow:loss = 0.035063308, step = 41000 (0.317 sec)\n",
      "INFO:tensorflow:global_step/sec: 323.443\n",
      "INFO:tensorflow:loss = 0.022310834, step = 41100 (0.309 sec)\n",
      "INFO:tensorflow:global_step/sec: 334.224\n",
      "INFO:tensorflow:loss = 0.017117575, step = 41200 (0.298 sec)\n",
      "INFO:tensorflow:global_step/sec: 329.825\n",
      "INFO:tensorflow:loss = 0.0077473857, step = 41300 (0.304 sec)\n",
      "INFO:tensorflow:global_step/sec: 345.749\n",
      "INFO:tensorflow:loss = 0.02366779, step = 41400 (0.289 sec)\n",
      "INFO:tensorflow:global_step/sec: 329.827\n",
      "INFO:tensorflow:loss = 0.012214128, step = 41500 (0.302 sec)\n",
      "INFO:tensorflow:global_step/sec: 339.889\n",
      "INFO:tensorflow:loss = 0.034124717, step = 41600 (0.294 sec)\n",
      "INFO:tensorflow:global_step/sec: 351.815\n",
      "INFO:tensorflow:loss = 0.0062106894, step = 41700 (0.285 sec)\n",
      "INFO:tensorflow:global_step/sec: 339.889\n",
      "INFO:tensorflow:loss = 0.0098359175, step = 41800 (0.294 sec)\n",
      "INFO:tensorflow:global_step/sec: 295.773\n",
      "INFO:tensorflow:loss = 0.03374955, step = 41900 (0.337 sec)\n",
      "INFO:tensorflow:global_step/sec: 344.561\n",
      "INFO:tensorflow:loss = 0.0061729928, step = 42000 (0.291 sec)\n",
      "INFO:tensorflow:global_step/sec: 348.151\n",
      "INFO:tensorflow:loss = 0.012070702, step = 42100 (0.286 sec)\n",
      "INFO:tensorflow:global_step/sec: 302.922\n",
      "INFO:tensorflow:loss = 0.01694083, step = 42200 (0.330 sec)\n",
      "INFO:tensorflow:global_step/sec: 328.745\n",
      "INFO:tensorflow:loss = 0.011122708, step = 42300 (0.304 sec)\n",
      "INFO:tensorflow:global_step/sec: 350.585\n",
      "INFO:tensorflow:loss = 0.023092808, step = 42400 (0.286 sec)\n",
      "INFO:tensorflow:global_step/sec: 348.151\n",
      "INFO:tensorflow:loss = 0.035293855, step = 42500 (0.287 sec)\n",
      "INFO:tensorflow:global_step/sec: 313.335\n",
      "INFO:tensorflow:loss = 0.013393877, step = 42600 (0.319 sec)\n",
      "INFO:tensorflow:global_step/sec: 297.529\n",
      "INFO:tensorflow:loss = 0.0011325097, step = 42700 (0.335 sec)\n",
      "INFO:tensorflow:global_step/sec: 311.387\n",
      "INFO:tensorflow:loss = 0.058121845, step = 42800 (0.322 sec)\n",
      "INFO:tensorflow:global_step/sec: 330.917\n",
      "INFO:tensorflow:loss = 0.00463884, step = 42900 (0.302 sec)\n",
      "INFO:tensorflow:global_step/sec: 277.748\n",
      "INFO:tensorflow:loss = 0.0624175, step = 43000 (0.362 sec)\n",
      "INFO:tensorflow:global_step/sec: 317.302\n",
      "INFO:tensorflow:loss = 0.004327948, step = 43100 (0.313 sec)\n",
      "INFO:tensorflow:global_step/sec: 330.916\n",
      "INFO:tensorflow:loss = 0.011105306, step = 43200 (0.302 sec)\n",
      "INFO:tensorflow:global_step/sec: 327.671\n",
      "INFO:tensorflow:loss = 0.026352905, step = 43300 (0.304 sec)\n",
      "INFO:tensorflow:global_step/sec: 317.301\n",
      "INFO:tensorflow:loss = 0.012109724, step = 43400 (0.317 sec)\n",
      "INFO:tensorflow:global_step/sec: 325.543\n",
      "INFO:tensorflow:loss = 0.0085020205, step = 43500 (0.307 sec)\n",
      "INFO:tensorflow:global_step/sec: 306.628\n",
      "INFO:tensorflow:loss = 0.0046698563, step = 43600 (0.325 sec)\n",
      "INFO:tensorflow:global_step/sec: 323.443\n",
      "INFO:tensorflow:loss = 0.0056218114, step = 43700 (0.309 sec)\n",
      "INFO:tensorflow:global_step/sec: 321.369\n",
      "INFO:tensorflow:loss = 0.009052013, step = 43800 (0.311 sec)\n",
      "INFO:tensorflow:global_step/sec: 306.628\n",
      "INFO:tensorflow:loss = 0.004092439, step = 43900 (0.326 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 44000 into C:\\Users\\link\\AppData\\Local\\Temp\\tmp11s3czce\\model.ckpt.\n",
      "INFO:tensorflow:Loss for final step: 0.0025847908.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.estimator.canned.dnn.DNNClassifier at 0x26bd31efa90>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature_cols = [tf.feature_column.numeric_column(\"X\", shape=[28 * 28])]\n",
    "dnn_clf = tf.estimator.DNNClassifier(\n",
    "    hidden_units=[300,100],\n",
    "    n_classes=10,\n",
    "    feature_columns=feature_cols\n",
    ")\n",
    "\n",
    "input_fn = tf.estimator.inputs.numpy_input_fn(\n",
    "    x={\"X\": X_train},\n",
    "    y=y_train,\n",
    "    num_epochs=40,\n",
    "    batch_size=50,\n",
    "    shuffle=True\n",
    ")\n",
    "\n",
    "dnn_clf.train(input_fn=input_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Starting evaluation at 2019-03-11-16:17:16\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from C:\\Users\\link\\AppData\\Local\\Temp\\tmp11s3czce\\model.ckpt-44000\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Finished evaluation at 2019-03-11-16:17:16\n",
      "INFO:tensorflow:Saving dict for global step 44000: accuracy = 0.9792, average_loss = 0.10099163, global_step = 44000, loss = 12.783751\n",
      "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 44000: C:\\Users\\link\\AppData\\Local\\Temp\\tmp11s3czce\\model.ckpt-44000\n"
     ]
    }
   ],
   "source": [
    "test_input_fn = tf.estimator.inputs.numpy_input_fn(\n",
    "    x={\"X\": X_test},\n",
    "    y=y_test,\n",
    "    shuffle=False\n",
    ")\n",
    "\n",
    "eval_results = dnn_clf.evaluate(input_fn=test_input_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'accuracy': 0.9792,\n",
       " 'average_loss': 0.10099163,\n",
       " 'loss': 12.783751,\n",
       " 'global_step': 44000}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eval_results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 10.3 텐서플로의 저수준 API로 심층 신경망 훈련하기"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 10.3.1 구성 단계"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "\n",
    "n_inputs = 28*28  # MNIST\n",
    "n_hidden1 = 300\n",
    "n_hidden2 = 100\n",
    "n_outputs = 10\n",
    "\n",
    "X = tf.placeholder(tf.float32, shape=(None, n_inputs), name=\"X\")\n",
    "y = tf.placeholder(tf.int32, shape=(None), name=\"y\")\n",
    "\n",
    "def neuron_layer(X, n_neurons, name, activation=None):\n",
    "    with tf.name_scope(name):\n",
    "        n_inputs = int(X.get_shape()[1])\n",
    "        stddev = 2 / np.sqrt(n_inputs)\n",
    "        init = tf.truncated_normal((n_inputs, n_neurons), stddev=stddev)\n",
    "        W = tf.Variable(init, name=\"kernel\")\n",
    "        b = tf.Variable(tf.zeros([n_neurons]), name=\"bias\")\n",
    "        Z = tf.matmul(X, W) + b\n",
    "        if activation is not None:\n",
    "            return activation(Z)\n",
    "        else:\n",
    "            return Z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.name_scope(\"dnn\"):\n",
    "    _hidden1 = neuron_layer(X, n_hidden1, name=\"_hidden1\", activation=tf.nn.relu)\n",
    "    _hidden2 = neuron_layer(_hidden1, n_hidden2, name=\"_hidden2\", activation=tf.nn.relu)\n",
    "    _logits = neuron_layer(_hidden2, n_outputs, name=\"_outputs\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.name_scope(\"dnn\"):\n",
    "    hidden1 = tf.layers.dense(X, n_hidden1, name=\"hidden1\", activation=tf.nn.relu)\n",
    "    hidden2 = tf.layers.dense(hidden1, n_hidden2, name=\"hidden2\", activation=tf.nn.relu)\n",
    "    logits = tf.layers.dense(hidden2, n_outputs, name=\"outputs\")\n",
    "    y_proba = tf.nn.softmax(logits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.name_scope(\"loss\"):\n",
    "    xentropy = tf.nn.sparse_softmax_cross_entropy_with_logits(labels=y, logits=logits)\n",
    "    loss = tf.reduce_mean(xentropy, name=\"loss\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 0.01\n",
    "\n",
    "with tf.name_scope(\"train\"):\n",
    "    optimizer = tf.train.GradientDescentOptimizer(learning_rate)\n",
    "    training_op = optimizer.minimize(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.name_scope(\"eval\"):\n",
    "    correct = tf.nn.in_top_k(logits, y, 1)\n",
    "    accuracy = tf.reduce_mean(tf.cast(correct, tf.float32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "init = tf.global_variables_initializer()\n",
    "saver = tf.train.Saver()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 10.3.2 실행 단계"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def shuffle_batch(X, y, batch_size):\n",
    "    rnd_idx = np.random.permutation(len(X))\n",
    "    n_batches = len(X) // batch_size\n",
    "    for batch_idx in np.array_split(rnd_idx, n_batches):\n",
    "        X_batch, y_batch = X[batch_idx], y[batch_idx]\n",
    "        yield X_batch, y_batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 배치 데이터 정확도: 0.86 검증 세트 정확도: 0.9042\n",
      "1 배치 데이터 정확도: 0.92 검증 세트 정확도: 0.9204\n",
      "2 배치 데이터 정확도: 0.9 검증 세트 정확도: 0.9324\n",
      "3 배치 데이터 정확도: 0.94 검증 세트 정확도: 0.9412\n",
      "4 배치 데이터 정확도: 0.94 검증 세트 정확도: 0.943\n",
      "5 배치 데이터 정확도: 0.88 검증 세트 정확도: 0.948\n",
      "6 배치 데이터 정확도: 0.88 검증 세트 정확도: 0.9508\n",
      "7 배치 데이터 정확도: 0.94 검증 세트 정확도: 0.9542\n",
      "8 배치 데이터 정확도: 0.94 검증 세트 정확도: 0.9574\n",
      "9 배치 데이터 정확도: 1.0 검증 세트 정확도: 0.9596\n",
      "10 배치 데이터 정확도: 0.98 검증 세트 정확도: 0.9622\n",
      "11 배치 데이터 정확도: 0.94 검증 세트 정확도: 0.9642\n",
      "12 배치 데이터 정확도: 0.98 검증 세트 정확도: 0.9662\n",
      "13 배치 데이터 정확도: 0.96 검증 세트 정확도: 0.9664\n",
      "14 배치 데이터 정확도: 0.96 검증 세트 정확도: 0.9684\n",
      "15 배치 데이터 정확도: 1.0 검증 세트 정확도: 0.9698\n",
      "16 배치 데이터 정확도: 1.0 검증 세트 정확도: 0.9684\n",
      "17 배치 데이터 정확도: 0.98 검증 세트 정확도: 0.9702\n",
      "18 배치 데이터 정확도: 1.0 검증 세트 정확도: 0.9718\n",
      "19 배치 데이터 정확도: 0.98 검증 세트 정확도: 0.9732\n"
     ]
    }
   ],
   "source": [
    "n_epochs = 20\n",
    "n_batches = 50\n",
    "batch_size = 50\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    init.run()\n",
    "    for epoch in range(n_epochs):\n",
    "        for X_batch, y_batch in shuffle_batch(X_train, y_train, batch_size):\n",
    "            sess.run(training_op, feed_dict={X: X_batch, y: y_batch})\n",
    "        acc_batch = accuracy.eval(feed_dict={X: X_batch, y: y_batch})\n",
    "        acc_valid = accuracy.eval(feed_dict={X: X_valid, y: y_valid})\n",
    "        print(epoch, \"배치 데이터 정확도:\", acc_batch, \"검증 세트 정확도:\", acc_valid)\n",
    "\n",
    "    save_path = saver.save(sess, \"./my_model_final.ckpt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 10.3.3 신경망 사용하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from ./my_model_final.ckpt\n"
     ]
    }
   ],
   "source": [
    "with tf.Session() as sess:\n",
    "    saver.restore(sess, \"./my_model_final.ckpt\")\n",
    "    X_new_scaled = X_test[:20]\n",
    "    Z = logits.eval(feed_dict={X: X_new_scaled})\n",
    "    y_pred = np.argmax(Z, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "예측 클래스: [7 2 1 0 4 1 4 9 6 9 0 6 9 0 1 5 9 7 3 4]\n",
      "타깃 클래스: [7 2 1 0 4 1 4 9 5 9 0 6 9 0 1 5 9 7 3 4]\n"
     ]
    }
   ],
   "source": [
    "print(\"예측 클래스:\", y_pred)\n",
    "print(\"타깃 클래스:\", y_test[:20])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 10.4 신경망 하이퍼파라미터 튜닝하기"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "+ 신경망의 유연성은 중요한 단점이 되기도 함 → 조절해야 할 하이퍼파라미터가 많아짐\n",
    "+ 튜닝방법\n",
    "    + 교차 검증을 활용한 그리드 탐색, 랜덤 탐색\n",
    "    + 오스카<sup>Oscar</sup>(http://oscar.calldesk.ai/)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 10.4.1 은닉층의 수"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "+ 은닉층이 하나인 다층 퍼셉트론이더라도 뉴런 수가 충분하면 아주 복잡한 함수도 모델링할 수 있음\n",
    "+ 하지만 심층 신경망이 얕은 신경망보다 **파라미터 효율성**이 훨씬 좋음\n",
    "+ 훈련 세트에 과대적합이 생기기 전까지 점진적으로 은닉층의 수를 늘릴 수 있음\n",
    "+ 미리 훈련된 네트워크 일부를 **재사용**할 수 있음"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 10.4.2 은닉층의 뉴런 수"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "+ 입력층과 출력층의 뉴런 수는 해당 작업에 필요한 입력과 출력의 형태에 따라 결정됨\n",
    "    + MNIST는 28×28=784개의 입력 뉴런과 10개의 출력 뉴런\n",
    "+ 모든 은닉층에 같은 뉴런의 크기를 사용하면 하이퍼파라미터를 층마다 따로 설정하지 않아도 됨\n",
    "+ 네트워크가 과대적합이 시작되기 전까지 점진적으로 뉴런 수를 늘릴 수 있음\n",
    "+ 일반적으로 층의 뉴런 수보다 층 수를 늘리는 쪽이 이득이 많음\n",
    "+ **스트레치 팬츠**<sup>stretch pants</sup> 방식 : 실제 필요한 것보다 더 많은 층과 뉴런을 가진 모델을 선택하고, 과대적합되지 않도록 조기 종료 기법을 사용"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 10.4.3 활성화 함수"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "+ 대부분의 은닉층에 **ReLU** 활성화 함수를 사용\n",
    "    + 다른 활성화 함수보다 계산이 조금 더 빠름\n",
    "    + 입력값이 클 때 특정 값에 수렴하지 않는 덕분에 경사 하강법이 평편한 지역에서 심하게 지체되지 않음\n",
    "+ 클래스가 상호 배타적일 경우 출력층에서는 일반적으로 **소프트맥스** 함수를 사용\n",
    "+ 회귀 작업일 경우에는 출력층에서 활성화 함수를 사용하지 않음"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 10.5 연습문제"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. ([그림 10-3]에 있는 것과 같은) 초창기 인공 뉴런을 사용해 $A⊕B$(⊕는 XOR 연산입니다)를 계산하는 인공신경망을 그려보세요. 힌트: $A⊕B = (A ∧ ¬B) ∨ (¬A ∧ B).$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Figure10-10](./images/Figure10-10.png)\n",
    "**<center>그림 10-10 연습문제 1</center>**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. 고전적인 퍼셉트론(즉, 퍼셉트론 훈련 알고리즘으로 훈련된 단일 TLU)보다 로지스틱 회귀 분류기가 일반적으로 선호되는 이유는 무엇인가요? 퍼셉트론을 어떻게 수정하면 로지스틱 회귀 분류기와 동등하게 만들 수 있나요?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "☞ 고전적인 퍼셉트론은 데이터셋이 선형적으로 구분될 때만 수렴하고 클래스 확률을 추정할 수 없습니다. 이와는 반대로 로지스틱 회귀 분류기는 데이터셋이 선형적으로 구분되지 못 해도 좋은 솔루션으로 수렴하고 클래스 확률을 출력합니다. 퍼셉트론의 활성화 함수를 로지스틱 활성화 함수로(또는 여러 개의 뉴런일 경우 소프트맥스 활성화 함수로) 바꾸고, 경사 하강법을 사용하여(또는 크로스 엔트로피 같은 비용 함수를 최소화하는 다른 최적화 알고리즘을 사용하여) 훈련시키면 로지스틱 회귀 분류기와 동일하게 됩니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3. 왜 초창기의 다층 퍼셉트론을 훈련시킬 때 로지스틱 활설화 함수가 핵심 요소였나요?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "☞ 로지스틱 활성화 함수의 도함수는 어디에서나 0이 아니어서 경사 하강법이 항상 경사를 따라 이동할 수 있으므로 초창기 MLP의 핵심 요소였습니다. 활성화 함수가 계단 함수일 때는 경사가 없기 때문에 경사 하강법이 이동할 수 없습니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4. 유명한 활성화 함수 네 가지는 무엇인가요?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Figure10-8](./images/Figure10-8.png)\n",
    "**<center>그림 10-8 활성화 함수와 해당 도함수</center>**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5. 10개의 통과 뉴런으로 된 입력층, 50개의 뉴런으로 된 은닉층, 그리고 3개의 뉴런으로 된 출력층으로 구성된 다층 퍼셉트론이 있다고 가정합시다. 모든 뉴런은 ReLU 활성화 함수를 사용합니다.\n",
    "+ **입력 행렬 $X$의 크기는 얼마인가요?**  \n",
    "☞ m×10 (m은 훈련 배치의 크기)\n",
    "+ **은닉층의 가중치 벡터 $W$<sub>$h$</sub>와 편향 벡터 $b$<sub>$h$</sub>의 크기는 얼마인가요?**  \n",
    "☞ 10×50, 50\n",
    "+ **출력층의 가중치 벡터 $W$<sub>$o$</sub>와 편향 벡터 $b$<sub>$o$</sub>의 크기는 얼마인가요?**  \n",
    "☞ 50×3, 3\n",
    "+ **네트워크의 출력 행렬 $Y$의 크기는 얼마인가요?**  \n",
    "☞ m×3\n",
    "+ **$X$, $W$<sub>$h$</sub>, $b$<sub>$h$</sub>, $W$<sub>$o$</sub>, b<sub>$o$</sub>의 함수로 네트워크의 출력 행렬 Y를 계산하는 식을 써보세요.**  \n",
    "☞ $Y$ = ReLU(ReLU($X$·$W$<sub>h</sub> + $b$<sub>h</sub>)·$W$<sub>$o$</sub> + $b$<sub>$o$</sub>)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 6. 스팸 메일을 분류하기 위해서는 출력층에 몇 개의 뉴런이 필요할까요? 출력층에 어떤 활성화 함수를 사용해야 할까요? MNIST 문제라면 출력층에 어떤 활성화 함수를 사용하고 뉴런은 몇 개가 필요할까요? 2장에서 본 주택 가격 예측용 네트워크에 대해 같은 질문의 답을 찾아보세요."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "☞ 스팸 메일을 분류하기 위해서는 신경망의 출력층에 하나의 뉴런만 필요합니다. 예를 들어 이메일이 스팸일 확률을 출력합니다. 확률을 추정할 때 일반적으로 출력층에 로지스틱(Sigmoid) 활성화 함수를 사용합니다. MNIST 문제라면 출력층에 10개의 뉴런이 필요하고, 다중 클래스 환경에서 클래스마다 하나의 확률을 출력하기 위해 로지스틱 함수를 소프트맥스 활성화 함수로 바꾸어야 합니다. 2장에서처럼 주택 가격을 예측하는 신경망을 만들고 싶다면 출력층에 활성화 함수가 없는 출력 뉴런 하나가 필요합니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 7. 역전파란 무엇이고 어떻게 작동하나요? 역전파와 후진 모드 자동 미분의 차이점은 무엇인가요?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Figure10-7-1](./images/Figure10-7-1.png)\n",
    "**<center>그림 10-7-1 Backpropagation</center>**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "+ **역전파** : 그래디언트 계산과 경사 하강법 스텝을 여러 번 수행하여 인공 신경망을 훈련시키는 전체 프로세스\n",
    "+ **후진 모드 자동 미분** : 그래디언트를 효과적으로 계산하는 하나의 기법"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 8. 다층 퍼셉트론에서 조정할 수 있는 하이퍼파라미터를 모두 나열해보세요. 훈련 데이터에 다층 퍼셉트론이 과대적합되었다면 이를 해결하기 위해 하이퍼파라미터를 어떻게 조정해야 할까요?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "☞ 기본 MLP에서 바꿀 수 있는 하이퍼파라미터는 은닉층 수, 각 은닉층의 뉴런 수, 각 은닉층과 출력층에서 사용하는 활성화 함수입니다. 일반적으로 ReLU(또는 이 함수의 변종)가 은닉층의 활성화 함수 기본값으로 좋습니다. 출력층에서는 일반적으로 이진 분류에서는 로지스틱 활성화 함수, 다중 분류에서는 소프트맥스 활성화 함수를 사용하고 회귀에서는 활성화 함수를 적용하지 않습니다.  \n",
    "☞ MLP가 훈련 데이터에 과대적합되었다면 은닉층 수와 각 은닉층에 있는 뉴런 수를 줄여볼 수 있습니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 9. 깊은<sup>deep</sup> 다층 퍼셉트론을 MNIST 데이터셋에 훈련시키고 98% 정확도를 얻을 수 있는지 확인해보세요. 9장의 마지막 연습문제에서와 같이 모든 부가 기능을 추가해보세요(즉, 체크포인트를 저장하고, 중지되었을 때 마지막 체크포인트를 복원하고, 서머리를 추가하고, 텐서보드를 사용해 학습 곡선을 그려보세요)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "\n",
    "(X_train, y_train), (X_test, y_test) = tf.keras.datasets.mnist.load_data()\n",
    "X_train.shape, y_train.shape ,X_test.shape, y_test.shape\n",
    "X_train = X_train.astype(np.float32).reshape(-1, 28*28) / 255.0\n",
    "X_test = X_test.astype(np.float32).reshape(-1, 28*28) / 255.0\n",
    "y_train = y_train.astype(np.int32)\n",
    "y_test = y_test.astype(np.int32)\n",
    "X_valid, X_train = X_train[:5000], X_train[5000:]\n",
    "y_valid, y_train = y_train[:5000], y_train[5000:]\n",
    "\n",
    "n_inputs = 28*28  # MNIST\n",
    "n_hidden1 = 300\n",
    "n_hidden2 = 100\n",
    "n_outputs = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = tf.placeholder(tf.float32, shape=(None, n_inputs), name=\"X\")\n",
    "y = tf.placeholder(tf.int32, shape=(None), name=\"y\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.name_scope(\"dnn\"):\n",
    "    hidden1 = tf.layers.dense(X, n_hidden1, name=\"hidden1\", activation=tf.nn.relu)\n",
    "    hidden2 = tf.layers.dense(hidden1, n_hidden2, name=\"hidden2\", activation=tf.nn.relu)\n",
    "    logits = tf.layers.dense(hidden2, n_outputs, name=\"outputs\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.name_scope(\"loss\"):\n",
    "    xentropy = tf.nn.sparse_softmax_cross_entropy_with_logits(labels=y, logits=logits)\n",
    "    loss = tf.reduce_mean(xentropy, name=\"loss\")\n",
    "    loss_summary = tf.summary.scalar('log_loss', loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 0.01\n",
    "\n",
    "with tf.name_scope(\"train\"):\n",
    "    optimizer = tf.train.GradientDescentOptimizer(learning_rate)\n",
    "    training_op = optimizer.minimize(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.name_scope(\"eval\"):\n",
    "    correct = tf.nn.in_top_k(logits, y, 1)\n",
    "    accuracy = tf.reduce_mean(tf.cast(correct, tf.float32))\n",
    "    accuracy_summary = tf.summary.scalar('accuracy', accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "init = tf.global_variables_initializer()\n",
    "saver = tf.train.Saver()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "\n",
    "def log_dir(prefix=\"\"):\n",
    "    now = datetime.utcnow().strftime(\"%Y%m%d%H%M%S\")\n",
    "    root_logdir = \"tf_logs\"\n",
    "    if prefix:\n",
    "        prefix += \"-\"\n",
    "    name = prefix + \"run-\" + now\n",
    "    return \"{}/{}/\".format(root_logdir, name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "logdir = log_dir(\"mnist_dnn\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_writer = tf.summary.FileWriter(logdir, tf.get_default_graph())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(55000, 784)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m, n = X_train.shape\n",
    "m, n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def shuffle_batch(X, y, batch_size):\n",
    "    rnd_idx = np.random.permutation(len(X))\n",
    "    n_batches = len(X) // batch_size\n",
    "    for batch_idx in np.array_split(rnd_idx, n_batches):\n",
    "        X_batch, y_batch = X[batch_idx], y[batch_idx]\n",
    "        yield X_batch, y_batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "에포크: 0 \t검증 세트 정확도: 89.980% \t손실: 0.35609\n",
      "에포크: 5 \t검증 세트 정확도: 95.080% \t손실: 0.17742\n",
      "에포크: 10 \t검증 세트 정확도: 96.260% \t손실: 0.13394\n",
      "에포크: 15 \t검증 세트 정확도: 97.020% \t손실: 0.10702\n",
      "에포크: 20 \t검증 세트 정확도: 97.400% \t손실: 0.09347\n",
      "에포크: 25 \t검증 세트 정확도: 97.640% \t손실: 0.08430\n",
      "에포크: 30 \t검증 세트 정확도: 97.600% \t손실: 0.07822\n",
      "에포크: 35 \t검증 세트 정확도: 97.740% \t손실: 0.07499\n",
      "에포크: 40 \t검증 세트 정확도: 97.760% \t손실: 0.07025\n",
      "에포크: 45 \t검증 세트 정확도: 97.880% \t손실: 0.06778\n",
      "에포크: 50 \t검증 세트 정확도: 97.820% \t손실: 0.06809\n",
      "에포크: 55 \t검증 세트 정확도: 98.060% \t손실: 0.06550\n",
      "에포크: 60 \t검증 세트 정확도: 98.080% \t손실: 0.06627\n",
      "에포크: 65 \t검증 세트 정확도: 98.120% \t손실: 0.06586\n",
      "에포크: 70 \t검증 세트 정확도: 98.060% \t손실: 0.06703\n",
      "에포크: 75 \t검증 세트 정확도: 97.980% \t손실: 0.06788\n",
      "에포크: 80 \t검증 세트 정확도: 98.040% \t손실: 0.06856\n",
      "에포크: 85 \t검증 세트 정확도: 98.120% \t손실: 0.06758\n",
      "에포크: 90 \t검증 세트 정확도: 98.160% \t손실: 0.06774\n",
      "에포크: 95 \t검증 세트 정확도: 98.200% \t손실: 0.06803\n",
      "에포크: 100 \t검증 세트 정확도: 98.040% \t손실: 0.06871\n",
      "에포크: 105 \t검증 세트 정확도: 98.200% \t손실: 0.06920\n",
      "조기 종료\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "n_epochs = 10001\n",
    "batch_size = 50\n",
    "n_batches = int(np.ceil(m / batch_size))\n",
    "\n",
    "checkpoint_path = \"/tmp/my_deep_mnist_model.ckpt\"\n",
    "checkpoint_epoch_path = checkpoint_path + \".epoch\"\n",
    "final_model_path = \"./my_deep_mnist_model\"\n",
    "\n",
    "best_loss = np.infty\n",
    "epochs_without_progress = 0\n",
    "max_epochs_without_progress = 50\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    if os.path.isfile(checkpoint_epoch_path):\n",
    "        # 체크포인트 파일이 있으면 모델을 복원하고 에포크 숫자를 로드합니다\n",
    "        with open(checkpoint_epoch_path, \"rb\") as f:\n",
    "            start_epoch = int(f.read())\n",
    "        print(\"이전 훈련이 중지되었습니다. 에포크 {}에서 시작합니다\".format(start_epoch))\n",
    "        saver.restore(sess, checkpoint_path)\n",
    "    else:\n",
    "        start_epoch = 0\n",
    "        sess.run(init)\n",
    "\n",
    "    for epoch in range(start_epoch, n_epochs):\n",
    "        for X_batch, y_batch in shuffle_batch(X_train, y_train, batch_size):\n",
    "            sess.run(training_op, feed_dict={X: X_batch, y: y_batch})\n",
    "        accuracy_val, loss_val, accuracy_summary_str, loss_summary_str = \n",
    "        sess.run([accuracy, loss, accuracy_summary, loss_summary], feed_dict={X: X_valid, y: y_valid})\n",
    "        \n",
    "        file_writer.add_summary(accuracy_summary_str, epoch)\n",
    "        file_writer.add_summary(loss_summary_str, epoch)\n",
    "        if epoch % 5 == 0:\n",
    "            print(\"에포크:\", epoch,\n",
    "                  \"\\t검증 세트 정확도: {:.3f}%\".format(accuracy_val * 100),\n",
    "                  \"\\t손실: {:.5f}\".format(loss_val))\n",
    "            saver.save(sess, checkpoint_path)\n",
    "            with open(checkpoint_epoch_path, \"wb\") as f:\n",
    "                f.write(b\"%d\" % (epoch + 1))\n",
    "            if loss_val < best_loss:\n",
    "                saver.save(sess, final_model_path)\n",
    "                best_loss = loss_val\n",
    "            else:\n",
    "                epochs_without_progress += 5\n",
    "                if epochs_without_progress > max_epochs_without_progress:\n",
    "                    print(\"조기 종료\")\n",
    "                    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.remove(checkpoint_epoch_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from ./my_deep_mnist_model\n"
     ]
    }
   ],
   "source": [
    "with tf.Session() as sess:\n",
    "    saver.restore(sess, final_model_path)\n",
    "    accuracy_val = accuracy.eval(feed_dict={X: X_test, y: y_test})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9794"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_val"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
